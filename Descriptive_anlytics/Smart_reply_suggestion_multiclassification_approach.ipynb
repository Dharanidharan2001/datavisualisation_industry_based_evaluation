{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yatindma/Automated-Response-Suggestion-for-Email/blob/master/Smart_reply_suggestion_multiclassification_approach.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2c-6YuFhv-JH"
      },
      "source": [
        "**Smart Email Reply Suggestion**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Eob1MGEiJKb1"
      },
      "source": [
        "Email is one of the most popular modes of communication on the Web. Despite the recent increase in usage of\n",
        "social networks, email continues to be the primary medium\n",
        "for billions of users across the world to connect and share\n",
        "information. With the rapid increase in email overload, it\n",
        "has become increasingly challenging for users to process and\n",
        "respond to incoming messages. It can be especially time consuming to type email replies on a mobile device so to over come this solution we need to suggest some basic replies to the users so that it can be fast and convinient to reply an email <br><br>\n",
        "\n",
        "\n",
        "This is an end to end method to automatically generating short email responses. It generates semantically diverse suggestions that can be used as complete email responses. The system is currently used in Inbox by Gmail and is responsible for assisting with 10% of\n",
        "all mobile responses. <br>\n",
        "[Google smart reply suggestions](https://arxiv.org/pdf/1606.04870.pdf)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        },
        "colab_type": "code",
        "id": "4zq791T8qM4L",
        "outputId": "e47a4f14-7d3a-46c0-c453-44263db204d5"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from  tqdm import tqdm \n",
        "from tensorflow.python.keras.layers import Layer\n",
        "from tensorflow.python.keras import backend as K"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "colab_type": "code",
        "id": "04fl9zoQWSMn",
        "outputId": "8742f44c-cf63-4519-ea3a-29b8230ae56e"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6008/674103202.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Load the Drive helper and mount\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# This will prompt for authorization.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/drive'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
          ]
        }
      ],
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1VG8j7PVvM1y"
      },
      "source": [
        "**Regarding Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vxhCfhtvxf8n"
      },
      "source": [
        "The dataset which I am using is from multiple sources <br>[dataset link1](https://github.com/gabrielfarah/QA_Bot/blob/master/qa_dataset.csv)<br>\n",
        "[dataset link2](https://github.com/gabrielfarah/QA_Bot/blob/master/qa_dataset.csv)<br>\n",
        "[dataset link3](https://github.com/gabrielfarah/QA_Bot/blob/master/qa_dataset.csv)<br>\n",
        "\n",
        "This dataset contain small replies and later we cleaned some of the data as per the requirement."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lJ3o8wZwq-7-"
      },
      "source": [
        "#Reading the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "VFP4CLF-HvE7"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "arr = []\n",
        "question = []\n",
        "answer = []\n",
        "with open(\"data/train_data.txt\",\"rb\") as json_file:\n",
        "    data = json.load(json_file)\n",
        "    for data_ in data['data']:\n",
        "        for j,para in enumerate(data_['paragraphs']):\n",
        "          for k,qas in enumerate(para['qas']):\n",
        "            for ans in qas['answers']:\n",
        "              answer.append(ans['text'])\n",
        "              question.append(qas['question'])  \n",
        "              break\n",
        "        \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "GuEbrS23pkIq"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(list(zip(question, answer)), \n",
        "               columns =['question', 'reply']) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "colab_type": "code",
        "id": "lnwOPia1p5k1",
        "outputId": "f0a5940d-7034-42a7-a13a-a530a6872acb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>reply</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>86818</th>\n",
              "      <td>With what Belorussian city does Kathmandu have...</td>\n",
              "      <td>Minsk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86819</th>\n",
              "      <td>In what year did Kathmandu create its initial ...</td>\n",
              "      <td>1975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86820</th>\n",
              "      <td>What is KMC an initialism of?</td>\n",
              "      <td>Kathmandu Metropolitan City</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                question  \\\n",
              "86818  With what Belorussian city does Kathmandu have...   \n",
              "86819  In what year did Kathmandu create its initial ...   \n",
              "86820                      What is KMC an initialism of?   \n",
              "\n",
              "                             reply  \n",
              "86818                        Minsk  \n",
              "86819                         1975  \n",
              "86820  Kathmandu Metropolitan City  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.tail(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "NBdqNWapqFMj"
      },
      "outputs": [],
      "source": [
        "#Add more data to the above data \n",
        "df2 = pd.read_csv(\"data/qa_dataset.csv\", encoding = \"ISO-8859-1\", low_memory=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "colab_type": "code",
        "id": "qqAdoJoxsRy1",
        "outputId": "a0e45cf2-0940-4a31-e9fa-8aa4f9983706"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ArticleTitle</th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "      <th>DifficultyFromQuestioner</th>\n",
              "      <th>DifficultyFromAnswerer</th>\n",
              "      <th>ArticleFile</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Alessandro_Volta</td>\n",
              "      <td>Was Volta an Italian physicist?</td>\n",
              "      <td>yes</td>\n",
              "      <td>easy</td>\n",
              "      <td>easy</td>\n",
              "      <td>data/set4/a10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Alessandro_Volta</td>\n",
              "      <td>Is Volta buried in the city of Pittsburgh?</td>\n",
              "      <td>no</td>\n",
              "      <td>easy</td>\n",
              "      <td>easy</td>\n",
              "      <td>data/set4/a10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       ArticleTitle                                    Question Answer  \\\n",
              "0  Alessandro_Volta             Was Volta an Italian physicist?    yes   \n",
              "1  Alessandro_Volta  Is Volta buried in the city of Pittsburgh?     no   \n",
              "\n",
              "  DifficultyFromQuestioner DifficultyFromAnswerer    ArticleFile  \n",
              "0                     easy                   easy  data/set4/a10  \n",
              "1                     easy                   easy  data/set4/a10  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "tE0YSEe4sThm"
      },
      "outputs": [],
      "source": [
        "#Drop the columns which we don' need \n",
        "df2 = df2.drop(['ArticleTitle','DifficultyFromQuestioner','DifficultyFromAnswerer','ArticleFile'],axis =1 ) \n",
        "df2.columns = ['question', 'reply']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "colab_type": "code",
        "id": "mzaWi3EZZLz_",
        "outputId": "7eadc439-7edb-417e-869d-923eef002d18"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>reply</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>how long is this cord? the pictures looks like...</td>\n",
              "      <td>I took a photo: &lt;http://imgur.com/G48f1C4&gt;I bo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Has anyone used this to split a stereo signal?...</td>\n",
              "      <td>I believe this adapter yields a mono split and...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            question  \\\n",
              "0  how long is this cord? the pictures looks like...   \n",
              "1  Has anyone used this to split a stereo signal?...   \n",
              "\n",
              "                                               reply  \n",
              "0  I took a photo: <http://imgur.com/G48f1C4>I bo...  \n",
              "1  I believe this adapter yields a mono split and...  "
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df3 = pd.read_csv(\"data/music_questions.csv\")\n",
        "df3.columns = ['q','question', 'reply']\n",
        "df3.drop(['q'],axis = 1).head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "colab_type": "code",
        "id": "x6aEwo6JZMAG",
        "outputId": "52c29227-4dd1-4eae-a957-92bf299d4f95"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>reply</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>what are the colors that come in the package?</td>\n",
              "      <td>All colors seen on box plus Teal, Burgundy, Bl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>difference between meat cure and pickling salt</td>\n",
              "      <td>Pickling salt is a very pure form of salt. A m...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         question  \\\n",
              "0   what are the colors that come in the package?   \n",
              "1  difference between meat cure and pickling salt   \n",
              "\n",
              "                                               reply  \n",
              "0  All colors seen on box plus Teal, Burgundy, Bl...  \n",
              "1  Pickling salt is a very pure form of salt. A m...  "
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df4 = pd.read_csv(\"data/grocery_questions.csv\")\n",
        "df4.columns = ['q','question', 'reply']\n",
        "df4.drop(['q'],axis = 1).head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "A7SIqTqvz0Q8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "colab_type": "code",
        "id": "wWU5QWcXZL8e",
        "outputId": "d0057c03-854b-4a0c-9fec-3798b19dc0a5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>reply</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Yes, you will need to go to their website to d...</td>\n",
              "      <td>Yes, you will need to go to their website to d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>As long as it has a USB port it should work fi...</td>\n",
              "      <td>As long as it has a USB port it should work fi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            question  \\\n",
              "0  Yes, you will need to go to their website to d...   \n",
              "1  As long as it has a USB port it should work fi...   \n",
              "\n",
              "                                               reply  \n",
              "0  Yes, you will need to go to their website to d...  \n",
              "1  As long as it has a USB port it should work fi...  "
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df5 = pd.read_csv(\"data/video_game_qa.csv\")\n",
        "df5.columns = ['q','question', 'reply']\n",
        "df5.drop(['q'],axis = 1).head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "colab_type": "code",
        "id": "aH-rhfx5zv2x",
        "outputId": "8baf9e08-cfda-4d66-ae56-f26d110d0ab7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2917, 2)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "colab_type": "code",
        "id": "ucrubYE5zo8c",
        "outputId": "7902a5c0-dd3e-41e3-bf86-94cd13945d1d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(86821, 2)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "colab_type": "code",
        "id": "VFUxKIoBzx76",
        "outputId": "5a9d31ef-8f95-44f4-cae6-81dde83379ac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2976, 3)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df3.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "colab_type": "code",
        "id": "RCgU4bO0z1Rd",
        "outputId": "d9a3240e-d3a9-4171-aaec-a2d50d795863"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2997, 3)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df4.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "colab_type": "code",
        "id": "gpVTzea8z331",
        "outputId": "473b49c7-554d-459f-c377-fe8a2d5199d7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1183, 3)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df5.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "colab_type": "code",
        "id": "RkTwuBtOsbd1",
        "outputId": "c6dee7fa-0b5c-440f-c2c4-3f366e275ac3"
      },
      "outputs": [],
      "source": [
        "#Append both the dataset\n",
        "\n",
        "frames = [df, df2,df3,df4,df5]\n",
        "data = pd.concat(frames)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "colab_type": "code",
        "id": "Xy8bqNmEz7WB",
        "outputId": "13205a51-f19b-4ec1-ada1-a580a02f11fd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(96894, 3)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "colab_type": "code",
        "id": "dcDeBZIJhCYf",
        "outputId": "bf3364ca-26ca-4147-ec7d-c449599a9e1b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "290682"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "colab_type": "code",
        "id": "cOH9F02hsgQ1",
        "outputId": "3a0bc6c5-dba0-45cf-ddaf-a90b2f3847cf"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>reply</th>\n",
              "      <th>q</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1181</th>\n",
              "      <td>You can use it to replace the sticks on the ps...</td>\n",
              "      <td>You can use it to replace the sticks on the ps...</td>\n",
              "      <td>1181.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1182</th>\n",
              "      <td>it will work on macs, i got euro truck sim to ...</td>\n",
              "      <td>it will work on macs, i got euro truck sim to ...</td>\n",
              "      <td>1182.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               question  \\\n",
              "1181  You can use it to replace the sticks on the ps...   \n",
              "1182  it will work on macs, i got euro truck sim to ...   \n",
              "\n",
              "                                                  reply       q  \n",
              "1181  You can use it to replace the sticks on the ps...  1181.0  \n",
              "1182  it will work on macs, i got euro truck sim to ...  1182.0  "
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.tail(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "colab_type": "code",
        "id": "ovXoJqw8t3Xs",
        "outputId": "a47aac38-33c9-4bd0-99b2-d4cf7c46ceec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(96894, 3)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ldk5mCQBt73O"
      },
      "source": [
        "So we have nearly 90K data points "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1qo4-H8SujNE"
      },
      "source": [
        "#Data Cleaning and EDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "on9Jb9_lrjn6"
      },
      "source": [
        "**Converting data into lower case**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "colab_type": "code",
        "id": "1a33I75XrsmD",
        "outputId": "8057a3e9-7cff-424f-fc75-2e41a3855e2d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>reply</th>\n",
              "      <th>q</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>when did beyonce start becoming popular?</td>\n",
              "      <td>in the late 1990s</td>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>what areas did beyonce compete in when she was...</td>\n",
              "      <td>singing and dancing</td>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>when did beyonce leave destiny's child and bec...</td>\n",
              "      <td>2003</td>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>in what city and state did beyonce  grow up?</td>\n",
              "      <td>houston, texas</td>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            question                reply    q\n",
              "0           when did beyonce start becoming popular?    in the late 1990s  nan\n",
              "1  what areas did beyonce compete in when she was...  singing and dancing  nan\n",
              "2  when did beyonce leave destiny's child and bec...                 2003  nan\n",
              "3      in what city and state did beyonce  grow up?        houston, texas  nan"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = data.apply(lambda x: x.astype(str).str.lower())\n",
        "data.head(4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0ZJl1i9crzmH"
      },
      "source": [
        "**Removing all special characters from the data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "S-DY1AB7D1Ny"
      },
      "source": [
        "Removing the stop words from the questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "6kPqu53KD59D"
      },
      "outputs": [],
      "source": [
        "# https://gist.github.com/sebleier/554280\n",
        "# we are removing the words from the stop words list: 'no', 'nor', 'not'\n",
        "# <br /><br /> ==> after the above steps, we are getting \"br br\"\n",
        "# we are including them into stop words list\n",
        "# instead of <br /> if we have <br/> these tags would have revmoved in the 1st step\n",
        "\n",
        "stopwords= set(['br', 'the', 'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n",
        "            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n",
        "            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n",
        "            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n",
        "            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n",
        "            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n",
        "            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n",
        "            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n",
        "            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n",
        "            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n",
        "            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n",
        "            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n",
        "            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n",
        "            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n",
        "            'won', \"won't\", 'wouldn', \"wouldn't\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "H93GGu3uF5pa"
      },
      "outputs": [],
      "source": [
        "# https://stackoverflow.com/a/47091490/4084039\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "def decontracted(phrase):\n",
        "    # specific\n",
        "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
        "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
        "\n",
        "    # general\n",
        "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
        "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
        "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
        "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
        "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
        "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
        "    return phrase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "colab_type": "code",
        "id": "mw0PoKiOI8Ab",
        "outputId": "214ab2ed-6178-438e-a787-e4c2e39ec4c0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>reply</th>\n",
              "      <th>q</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>when did beyonce start becoming popular?</td>\n",
              "      <td>in the late 1990s</td>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>what areas did beyonce compete in when she was...</td>\n",
              "      <td>singing and dancing</td>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>when did beyonce leave destiny's child and bec...</td>\n",
              "      <td>2003</td>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>in what city and state did beyonce  grow up?</td>\n",
              "      <td>houston, texas</td>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>in which decade did beyonce become famous?</td>\n",
              "      <td>late 1990s</td>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            question                reply    q\n",
              "0           when did beyonce start becoming popular?    in the late 1990s  nan\n",
              "1  what areas did beyonce compete in when she was...  singing and dancing  nan\n",
              "2  when did beyonce leave destiny's child and bec...                 2003  nan\n",
              "3      in what city and state did beyonce  grow up?        houston, texas  nan\n",
              "4         in which decade did beyonce become famous?           late 1990s  nan"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "colab_type": "code",
        "id": "Y_JvWuW1Ez8Y",
        "outputId": "49eb13da-b51b-4623-ebd8-04c476d24f9c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 99%|█████████▉| 96254/96894 [00:41<00:00, 2336.70it/s]C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bs4\\__init__.py:337: MarkupResemblesLocatorWarning: \"....\" looks like a directory name, not markup. You may want to open a file found in this directory and pass the filehandle into Beautiful Soup.\n",
            "  warnings.warn(\n",
            "100%|██████████| 96894/96894 [00:42<00:00, 2290.20it/s]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "all_questions= []\n",
        "for sentence in tqdm(data['question'].values): \n",
        "    sentence = re.sub(r\"http\\S+\", \"\", sentence)\n",
        "    sentence = BeautifulSoup(sentence, 'lxml').get_text()\n",
        "    # sentence = decontracted(sentence)\n",
        "    sentence = re.sub(\"\\S*\\d\\S*\", \"\", sentence).strip()\n",
        "    sentence = re.sub('[^A-Za-z]+', ' ', sentence)   \n",
        "    # sentence = ' '.join(e.lower() for e in sentence.split() if e.lower() not in stopwords)\n",
        "    all_questions.append(sentence.strip())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "qE4Q2u1LrvXN"
      },
      "outputs": [],
      "source": [
        "#Putting all preprocessed data back to the dataframe\n",
        "data['question'] = all_questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8AkEuS28q9rM"
      },
      "source": [
        "We need to delete the data where Answers are not correct \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "colab_type": "code",
        "id": "vrCStIBdq9FO",
        "outputId": "492f4447-eda7-431d-fa28-3da43a6856a2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 96894/96894 [00:01<00:00, 48680.90it/s]\n"
          ]
        }
      ],
      "source": [
        "all_replies= []\n",
        "for sentence in tqdm(data['reply'].values): \n",
        "    sentence = re.sub(r\"http\\S+\", \"\", sentence)\n",
        "    sentence = re.sub(\"\\S*\\d\\S*\", \"\", sentence).strip()\n",
        "    sentence = re.sub('[^A-Za-z]+', ' ', sentence)   \n",
        "    all_replies.append(sentence.strip())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "srTXDp1csAuE"
      },
      "source": [
        "**Trimming the data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "FYtcjFIXr9wC"
      },
      "outputs": [],
      "source": [
        "data = data.applymap(lambda x: x.strip() if isinstance(x, str) else x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "v4rwlo2_vJUt"
      },
      "source": [
        "Here we'll not drop the duplicate question as we'll be using they will help us in getting multiple replies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "colab_type": "code",
        "id": "C-wWnQQ8u_4v",
        "outputId": "0d5efb47-95a1-4c31-92f8-d47d93fbef5b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(96894, 3)"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "colab_type": "code",
        "id": "esxm3Yx1fJTB",
        "outputId": "c7421c4f-3300-4541-a8f3-582d0acf3278"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                            question                reply  \\\n",
            "0            when did beyonce start becoming popular    in the late 1990s   \n",
            "1  what areas did beyonce compete in when she was...  singing and dancing   \n",
            "2  when did beyonce leave destiny s child and bec...                 2003   \n",
            "3         in what city and state did beyonce grow up       houston, texas   \n",
            "4          in which decade did beyonce become famous           late 1990s   \n",
            "\n",
            "     q  reply_length  \n",
            "0  nan             4  \n",
            "1  nan             3  \n",
            "2  nan             1  \n",
            "3  nan             2  \n",
            "4  nan             2  \n",
            "417415\n"
          ]
        }
      ],
      "source": [
        "#get the length of the replies\n",
        "len_str_arr = []\n",
        "for sentence in data[\"reply\"].values:\n",
        "  len_str_arr.append(len(sentence.split()))\n",
        "\n",
        "\n",
        "\n",
        "data[\"reply_length\"]= len_str_arr\n",
        "\n",
        "data = data[(data.reply_length < 8)]\n",
        "print(data.head())\n",
        "\n",
        "\n",
        "len_str_arr_quest = []\n",
        "for sentence in data[\"question\"].values:\n",
        "  len_str_arr_quest.append(len(sentence.split()))\n",
        "\n",
        "\n",
        "data['question_length'] = len_str_arr_quest \n",
        "data = data[data.question_length < 100]\n",
        "print(data.size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-8m8NcbBseL_"
      },
      "source": [
        "We'll only take those reply only where the length is greater than 0 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "rxvkchtgsad5"
      },
      "outputs": [],
      "source": [
        "data = data[(data.reply_length > 0)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "colab_type": "code",
        "id": "PS1hDEKrfJS5",
        "outputId": "a001d733-7b12-4f78-be9d-c53d995ad0b9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(83483, 5)"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "IYZtxgiutgle"
      },
      "source": [
        "**We need to remove replies where grammer is not correct**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "5GqT0x1_tfLW"
      },
      "outputs": [],
      "source": [
        "#Code is copied form https://www.geeksforgeeks.org/check-given-sentence-given-set-simple-grammer-rules/\n",
        "# Method to check a given sentence for given rules \n",
        "def checkSentence(string): \n",
        "  \n",
        "    # Calculate the length of the string. \n",
        "    length = len(string) \n",
        "  \n",
        "    # Check that the first character lies in [A-Z]. \n",
        "    # Otherwise return false. \n",
        "    if string[0] < 'A' or string[0] > 'Z': \n",
        "        return False\n",
        "  \n",
        "    # Maintain 2 states. Previous and current state based \n",
        "    # on which vertex state you are. Initialise both with \n",
        "    # 0 = start state. \n",
        "    prev_state = 0\n",
        "    curr_state = 0\n",
        "  \n",
        "    # Keep the index to the next character in the string. \n",
        "    index = 1\n",
        "  \n",
        "    # Loop to go over the string. \n",
        "    while (string[index]): \n",
        "        # Set states according to the input characters in the \n",
        "        # string and the rule defined in the description. \n",
        "        # If current character is [A-Z]. Set current state as 0. \n",
        "        # if string[index] >= 'A' and string[index] <= 'Z': \n",
        "        #     curr_state = 0\n",
        "  \n",
        "        # If current character is a space. Set current state as 1. \n",
        "        if string[index] == ' ': \n",
        "            curr_state = 1\n",
        "  \n",
        "        # If current character is a space. Set current state as 2. \n",
        "        elif string[index] >= 'a' and string[index] <= 'z': \n",
        "            curr_state = 2\n",
        "  \n",
        "        # If current character is a space. Set current state as 3. \n",
        "        elif string[index] == '.': \n",
        "            curr_state = 3\n",
        "  \n",
        "        # Validates all current state with previous state for the \n",
        "        # rules in the description of the problem. \n",
        "        if prev_state == curr_state and curr_state != 2: \n",
        "            return False\n",
        "  \n",
        "        # If we have reached last state and previous state is not 1, \n",
        "        # then check next character. If next character is '\\0', then \n",
        "        # return true, else false \n",
        "        if prev_state == 2 and curr_state == 0: \n",
        "            return False\n",
        "  \n",
        "        # Set previous state as current state before going over \n",
        "        # to the next character. \n",
        "        if curr_state == 3 and prev_state != 1: \n",
        "            return True\n",
        "  \n",
        "        index += 1\n",
        "  \n",
        "        prev_state = curr_state \n",
        "  \n",
        "    return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "5sWf_sljueWl"
      },
      "outputs": [],
      "source": [
        "string = data['reply'].values\n",
        "string_size = len(string) \n",
        "grammar = []\n",
        "count = 0\n",
        "for i in range(string_size): \n",
        "    if checkSentence(string[i]): \n",
        "      grammar.append(1)\n",
        "      count+=1\n",
        "    else: \n",
        "      grammar.append(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "colab_type": "code",
        "id": "fWnPXOGqd8Zc",
        "outputId": "6666fe0a-d630-4258-e5e3-b2c7454ee170"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count # as here the count depict that out data is not coorect according to grammar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "X-2N9JhPfAQ0"
      },
      "source": [
        "the above approach for checking grammar is not working for this data set\n",
        "\n",
        "We need to change the approach to take where grammar is good"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Sp-f3fYufJS0"
      },
      "source": [
        "We didn't dopped more data :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "USXKkJTCfMXm"
      },
      "source": [
        "#Select only replies which are having more than 3 repetition in the dataset "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "colab_type": "code",
        "id": "reyvCMpWfSq1",
        "outputId": "e812d2d6-18d8-4ca6-ac19-0405f5855791"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 83483/83483 [18:24<00:00, 75.57it/s]\n"
          ]
        }
      ],
      "source": [
        "# Python3 program to find number of \n",
        "# times a string appears in an array. \n",
        "\n",
        "repeated_count = []\n",
        "# Returns count of occurrences of s in arr[] \n",
        "def search(arr, s): \n",
        "\tcounter = 0\n",
        "\tfor j in (range(len(arr))): \n",
        "\t\t\n",
        "\t\t# checking if string given in query \n",
        "\t\t# is present in the given string. \n",
        "\t\t# If present, increase times \n",
        "\t\tif (s == (arr[j])): \n",
        "\t\t\tcounter += 1\n",
        "\n",
        "\treturn counter \n",
        "\n",
        "def answerQueries(arr, q): \n",
        "\tfor i in tqdm(range(len(q))): \n",
        "\t\trepeated_count.append(search(arr, q[i]))\n",
        "\n",
        "# Driver code /\n",
        "if __name__ == '__main__': \n",
        "\tarr = data['reply'].values \n",
        "\tq = data['reply'].values \n",
        "\tanswerQueries(arr, q) \n",
        "\n",
        "# This code is contributed \n",
        "# by PrinciRaj19992 from github\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "colab_type": "code",
        "id": "rSeA-EVVGdBD",
        "outputId": "d15cd9e2-6c9d-470c-cd36-9beae523b0b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total replies, repeated as well as not repeated  83483\n",
            "total replies more than 1 32638\n",
            "total replies more than 2 23112\n",
            "total replies more than 3 19053\n",
            "total replies more than 4 16725\n",
            "total replies more than 5 15105\n",
            "total replies more than 6 13863\n",
            "total replies more than 7 13037\n",
            "total replies more than 11 10351\n",
            "total replies more than 15 8737\n",
            "total replies more than 16 8465\n",
            "total replies more than 17 8176\n",
            "total replies more than 18 7798\n",
            "total replies more than 19 7456\n",
            "total replies more than 20 7176\n",
            "total replies more than 21 6966\n",
            "total replies more than 22 6790\n",
            "total replies more than 23 6560\n"
          ]
        }
      ],
      "source": [
        "count = 0\n",
        "for item in repeated_count:\n",
        "  if item > 0:\n",
        "    count += 1\n",
        "\n",
        "print(\"total replies, repeated as well as not repeated \",count)\n",
        "\n",
        "count = 0\n",
        "for item in repeated_count:\n",
        "  if item > 1:\n",
        "    count += 1\n",
        "\n",
        "print(\"total replies more than 1\",count)\n",
        "\n",
        "count = 0\n",
        "for item in repeated_count:\n",
        "  if item > 2:\n",
        "    count += 1\n",
        "\n",
        "print(\"total replies more than 2\",count)\n",
        "\n",
        "count = 0\n",
        "for item in repeated_count:\n",
        "  if item > 3:\n",
        "    count += 1\n",
        "\n",
        "print(\"total replies more than 3\",count)\n",
        "\n",
        "count = 0\n",
        "for item in repeated_count:\n",
        "  if item > 4:\n",
        "    count += 1\n",
        "\n",
        "print(\"total replies more than 4\",count)\n",
        "\n",
        "count = 0\n",
        "for item in repeated_count:\n",
        "  if item > 5:\n",
        "    count += 1\n",
        "\n",
        "print(\"total replies more than 5\",count)\n",
        "\n",
        "count = 0\n",
        "for item in repeated_count:\n",
        "  if item > 6:\n",
        "    count += 1\n",
        "\n",
        "print(\"total replies more than 6\",count)\n",
        "\n",
        "\n",
        "count = 0\n",
        "for item in repeated_count:\n",
        "  if item > 7:\n",
        "    count += 1\n",
        "\n",
        "print(\"total replies more than 7\",count)\n",
        "\n",
        "count = 0\n",
        "for item in repeated_count:\n",
        "  if item > 11:\n",
        "    count += 1\n",
        "\n",
        "print(\"total replies more than 11\",count)\n",
        "\n",
        "count = 0\n",
        "for item in repeated_count:\n",
        "  if item > 15:\n",
        "    count += 1\n",
        "\n",
        "print(\"total replies more than 15\",count)\n",
        "\n",
        "\n",
        "count = 0\n",
        "for item in repeated_count:\n",
        "  if item > 16:\n",
        "    count += 1\n",
        "\n",
        "print(\"total replies more than 16\",count)\n",
        "\n",
        "\n",
        "\n",
        "count = 0\n",
        "for item in repeated_count:\n",
        "  if item > 17:\n",
        "    count += 1\n",
        "\n",
        "print(\"total replies more than 17\",count)\n",
        "\n",
        "\n",
        "\n",
        "count = 0\n",
        "for item in repeated_count:\n",
        "  if item > 18:\n",
        "    count += 1\n",
        "\n",
        "print(\"total replies more than 18\",count)\n",
        "\n",
        "\n",
        "\n",
        "count = 0\n",
        "for item in repeated_count:\n",
        "  if item > 19:\n",
        "    count += 1\n",
        "\n",
        "print(\"total replies more than 19\",count)\n",
        "\n",
        "count = 0\n",
        "for item in repeated_count:\n",
        "  if item > 20:\n",
        "    count += 1\n",
        "print(\"total replies more than 20\",count)\n",
        "\n",
        "count = 0\n",
        "for item in repeated_count:\n",
        "  if item > 21:\n",
        "    count += 1\n",
        "print(\"total replies more than 21\",count)    \n",
        "\n",
        "count = 0\n",
        "for item in repeated_count:\n",
        "  if item > 22:\n",
        "    count += 1\n",
        "print(\"total replies more than 22\",count)\n",
        "\n",
        "count = 0\n",
        "for item in repeated_count:\n",
        "  if item > 23:\n",
        "    count += 1\n",
        "\n",
        "print(\"total replies more than 23\",count)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lH9JhWwmHcHq"
      },
      "source": [
        "So we'll be selecting replies which are repeated more than 20 times<br>\n",
        "as mostly they will be correct as they are repeated multiple times"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "YtHO61XVGmPa"
      },
      "outputs": [],
      "source": [
        "data['repeated_reply_count'] = repeated_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "colab_type": "code",
        "id": "_NnABqhf2_NF",
        "outputId": "a5bea0dd-34fc-4468-e88a-284e93671fbb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>q</th>\n",
              "      <th>question</th>\n",
              "      <th>reply</th>\n",
              "      <th>reply_length</th>\n",
              "      <th>question_length</th>\n",
              "      <th>repeated_reply_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>nan</td>\n",
              "      <td>when did beyonce start becoming popular</td>\n",
              "      <td>in the late 1990s</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>nan</td>\n",
              "      <td>what areas did beyonce compete in when she was...</td>\n",
              "      <td>singing and dancing</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>nan</td>\n",
              "      <td>when did beyonce leave destiny s child and bec...</td>\n",
              "      <td>2003</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>nan</td>\n",
              "      <td>in what city and state did beyonce grow up</td>\n",
              "      <td>houston, texas</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>nan</td>\n",
              "      <td>in which decade did beyonce become famous</td>\n",
              "      <td>late 1990s</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     q  ... repeated_reply_count\n",
              "0  nan  ...                    1\n",
              "1  nan  ...                    1\n",
              "2  nan  ...                   47\n",
              "3  nan  ...                    1\n",
              "4  nan  ...                    5\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "execution_count": 40,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "lFoZTFN9rfDr"
      },
      "outputs": [],
      "source": [
        "data_new_15 = data[data.repeated_reply_count > 20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "CnFLo5M4uUzP"
      },
      "outputs": [],
      "source": [
        "data = data_new_15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "colab_type": "code",
        "id": "qUTxu2ZdH1Hm",
        "outputId": "2a8d3127-5575-447e-f411-0f4c70e9bfcb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>reply</th>\n",
              "      <th>q</th>\n",
              "      <th>reply_length</th>\n",
              "      <th>question_length</th>\n",
              "      <th>repeated_reply_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>when did beyonce leave destiny s child and bec...</td>\n",
              "      <td>2003</td>\n",
              "      <td>nan</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>when did beyonc release dangerously in love</td>\n",
              "      <td>2003</td>\n",
              "      <td>nan</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>how many grammy awards did beyonc win for her ...</td>\n",
              "      <td>five</td>\n",
              "      <td>nan</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>to set the record for grammys how many did bey...</td>\n",
              "      <td>six</td>\n",
              "      <td>nan</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>when did beyonce take a hiatus in her career a...</td>\n",
              "      <td>2010</td>\n",
              "      <td>nan</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>75</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             question reply    q  \\\n",
              "2   when did beyonce leave destiny s child and bec...  2003  nan   \n",
              "11        when did beyonc release dangerously in love  2003  nan   \n",
              "12  how many grammy awards did beyonc win for her ...  five  nan   \n",
              "17  to set the record for grammys how many did bey...   six  nan   \n",
              "19  when did beyonce take a hiatus in her career a...  2010  nan   \n",
              "\n",
              "    reply_length  question_length  repeated_reply_count  \n",
              "2              1               12                    47  \n",
              "11             1                7                    47  \n",
              "12             1               12                   140  \n",
              "17             1               11                    99  \n",
              "19             1               15                    75  "
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ky0I0p0vvxQD"
      },
      "source": [
        "Checking number of unique replies in the data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "LCw4_SLKxDtn"
      },
      "outputs": [],
      "source": [
        "unique_replies = (data_new_15.reply.unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "yk3Un-Ftz2GM"
      },
      "outputs": [],
      "source": [
        "total_unique_replies = len(unique_replies)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "colab_type": "code",
        "id": "x1mHfiCpIfHl",
        "outputId": "ecbf8919-3b1b-4546-91a7-b2059b9bc18d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "155\n"
          ]
        }
      ],
      "source": [
        "print(total_unique_replies)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Jw02axDEhW2Q"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Cp64LT6v0Foy"
      },
      "source": [
        "Let see which are top repeated replies "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "qbC2KFHW0VEJ"
      },
      "outputs": [],
      "source": [
        "reply_list = list(data['reply'].values)\n",
        "reply_dict = {i:reply_list.count(i) for i in reply_list}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "yNfvv1i12DjY"
      },
      "outputs": [],
      "source": [
        "from collections import OrderedDict\n",
        "reply_dict_sorted = OrderedDict(sorted(reply_dict.items(), key=lambda x: x[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "d32EpOzEmE7t"
      },
      "outputs": [],
      "source": [
        "reply = []\n",
        "keys = []\n",
        "for item in reply_dict_sorted.items():\n",
        "  reply.append(item[0])\n",
        "  keys.append(item[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "2oVVC9oqja57"
      },
      "outputs": [],
      "source": [
        "reply.reverse()\n",
        "keys.reverse()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "S_Ad6vx_8LhB"
      },
      "outputs": [],
      "source": [
        "#top 10 reply\n",
        "top_15_reply = reply[:15]\n",
        "top_15_keys = keys[:15]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "kmMETsW6-q8U"
      },
      "outputs": [],
      "source": [
        "temp_reply_list = []\n",
        "i = 0\n",
        "for key in top_15_keys:\n",
        "  for _ in range(0,key):\n",
        "    temp_reply_list.append(top_15_reply[i])\n",
        "  i += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sxzR9Cj8FhBF"
      },
      "source": [
        "<b>\n",
        "Article title can be used while giving the sentence for tokenizing later \n",
        "question do we need to preprocess the data\n",
        "reply mai kitne repeated h\n",
        "</b>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "colab_type": "code",
        "id": "iGGxT8LNFgjE",
        "outputId": "bd1929b6-3f56-4fdc-ed57-0fc7191a3d64"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABIoAAAEvCAYAAAAq+CoPAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAc1klEQVR4nO3df7RudV0n8PdHrmhqAcqN6MJ4KbGiUkFUzJmiMEepFczKn6uSjDVMjZVmNjKtZrw54wysmkwrLRIKG8cwtWQ1ljIoST9QL0gioHHDCAjlpoi/MgM/88f+Xjwc7r3ncs9zznPOua/XWnc9+/nuvZ/n+3zvfvbZ+72/+/tUdwcAAAAAHjDvCgAAAACwNgiKAAAAAEgiKAIAAABgEBQBAAAAkERQBAAAAMAgKAIAAAAgSbJp3hXYm8MPP7y3bt0672oAAAAAbBhXXnnlP3b35t3NW9NB0datW7N9+/Z5VwMAAABgw6iqm/Y0z61nAAAAACQRFAEAAAAwCIoAAAAASCIoAgAAAGAQFAEAAACQRFAEAAAAwCAoAgAAACCJoAgAAACAQVAEAAAAQBJBEQAAAACDoAgAAACAJMmmeVfgQLHtsm3zrgK7se3kbfOuAgAAAKwZehQBAAAAkERQBAAAAMAgKAIAAAAgiaAIAAAAgEFQBAAAAEASQREAAAAAg6AIAAAAgCSCIgAAAAAGQREAAAAASQRFAAAAAAyCIgAAAACSCIoAAAAAGARFAAAAACQRFAEAAAAwCIoAAAAASCIoAgAAAGAQFAEAAACQRFAEAAAAwCAoAgAAACCJoAgAAACAQVAEAAAAQBJBEQAAAACDoAgAAACAJIIiAAAAAAZBEQAAAABJBEUAAAAADEsGRVV1QVXdXlUfXlD28Kq6pKpuGI+HjfKqqtdU1Y6q+lBVnbBgnTPG8jdU1Rkr83EAAAAA2F/70qPod5M8fVHZ2Uku7e5jk1w6nifJM5IcO/6dleR1yRQsJXl5kicleWKSl+8KlwAAAABYG5YMirr7vUk+taj4tCQXjukLk5y+oPwNPbkiyaFVdWSSf5vkku7+VHffkeSS3Dd8AgAAAGCO9neMoiO6+7Yx/fEkR4zpLUluXrDcLaNsT+UAAAAArBHLHsy6uztJz6AuSZKqOquqtlfV9p07d87qZQEAAABYwv4GRZ8Yt5RlPN4+ym9NcvSC5Y4aZXsqv4/uPq+7T+zuEzdv3ryf1QMAAADg/trfoOjiJLt+ueyMJG9fUP788etnJyW5c9yi9s4kT6uqw8Yg1k8bZQAAAACsEZuWWqCq3pTk5CSHV9UtmX697Jwkb66qM5PclOTZY/F3JDk1yY4kX0jygiTp7k9V1X9L8oGx3Cu6e/EA2QAAAADM0ZJBUXc/bw+zTtnNsp3khXt4nQuSXHC/agcAAADAqln2YNYAAAAAbAyCIgAAAACSCIoAAAAAGARFAAAAACQRFAEAAAAwCIoAAAAASCIoAgAAAGAQFAEAAACQRFAEAAAAwCAoAgAAACCJoAgAAACAQVAEAAAAQBJBEQAAAACDoAgAAACAJIIiAAAAAAZBEQAAAABJBEUAAAAADIIiAAAAAJIIigAAAAAYBEUAAAAAJBEUAQAAADAIigAAAABIIigCAAAAYBAUAQAAAJBEUAQAAADAICgCAAAAIImgCAAAAIBBUAQAAABAEkERAAAAAIOgCAAAAIAkgiIAAAAABkERAAAAAEkERQAAAAAMgiIAAAAAkgiKAAAAABgERQAAAAAkWWZQVFU/U1XXVtWHq+pNVfXgqjqmqt5XVTuq6qKqOngs+6DxfMeYv3UmnwAAAACAmdjvoKiqtiT56SQndve3JTkoyXOTnJvkVd39qCR3JDlzrHJmkjtG+avGcgAAAACsEcu99WxTkq+qqk1JHpLktiTfk+QtY/6FSU4f06eN5xnzT6mqWub7AwAAADAj+x0UdfetSX45yd9nCojuTHJlkk93911jsVuSbBnTW5LcPNa9ayz/iP19fwAAAABmazm3nh2WqZfQMUm+PslDkzx9uRWqqrOqantVbd+5c+dyXw4AAACAfbScW8+emuRj3b2zu/8lyduSPCXJoeNWtCQ5KsmtY/rWJEcnyZh/SJJPLn7R7j6vu0/s7hM3b968jOoBAAAAcH8sJyj6+yQnVdVDxlhDpyS5Lsl7kjxzLHNGkreP6YvH84z57+7uXsb7AwAAADBDyxmj6H2ZBqW+Ksk147XOS/KyJC+pqh2ZxiA6f6xyfpJHjPKXJDl7GfUGAAAAYMY2Lb3InnX3y5O8fFHxjUmeuJtlv5jkWct5PwAAAABWznJuPQMAAABgAxEUAQAAAJBEUAQAAADAICgCAAAAIImgCAAAAIBBUAQAAABAEkERAAAAAIOgCAAAAIAkgiIAAAAABkERAAAAAEkERQAAAAAMgiIAAAAAkgiKAAAAABgERQAAAAAkERQBAAAAMAiKAAAAAEgiKAIAAABgEBQBAAAAkERQBAAAAMAgKAIAAAAgiaAIAAAAgEFQBAAAAEASQREAAAAAg6AIAAAAgCSCIgAAAAAGQREAAAAASQRFAAAAAAyCIgAAAACSCIoAAAAAGARFAAAAACQRFAEAAAAwCIoAAAAASCIoAgAAAGAQFAEAAACQRFAEAAAAwCAoAgAAACCJoAgAAACAYVlBUVUdWlVvqaqPVNX1VfXkqnp4VV1SVTeMx8PGslVVr6mqHVX1oao6YTYfAQAAAIBZWG6Polcn+dPu/uYkj01yfZKzk1za3ccmuXQ8T5JnJDl2/DsryeuW+d4AAAAAzNB+B0VVdUiS70xyfpJ095e6+9NJTkty4VjswiSnj+nTkryhJ1ckObSqjtzf9wcAAABgtpbTo+iYJDuT/E5VfbCqXl9VD01yRHffNpb5eJIjxvSWJDcvWP+WUQYAAADAGrCcoGhTkhOSvK67j0/y+XzlNrMkSXd3kr4/L1pVZ1XV9qravnPnzmVUDwAAAID7YzlB0S1Jbunu943nb8kUHH1i1y1l4/H2Mf/WJEcvWP+oUXYv3X1ed5/Y3Sdu3rx5GdUDAAAA4P7Y76Couz+e5Oaq+qZRdEqS65JcnOSMUXZGkreP6YuTPH/8+tlJSe5ccIsaAAAAAHO2aZnr/1SSN1bVwUluTPKCTOHTm6vqzCQ3JXn2WPYdSU5NsiPJF8ayAAAAAKwRywqKuvvqJCfuZtYpu1m2k7xwOe8HAAAAwMpZzhhFAAAAAGwggiIAAAAAkgiKAAAAABgERQAAAAAkERQBAAAAMAiKAAAAAEgiKAIAAABgEBQBAAAAkERQBAAAAMAgKAIAAAAgiaAIAAAAgEFQBAAAAEASQREAAAAAg6AIAAAAgCSCIgAAAAAGQREAAAAASQRFAAAAAAyCIgAAAACSCIoAAAAAGARFAAAAACQRFAEAAAAwCIoAAAAASCIoAgAAAGAQFAEAAACQRFAEAAAAwCAoAgAAACCJoAgAAACAQVAEAAAAQBJBEQAAAACDoAgAAACAJIIiAAAAAAZBEQAAAABJBEUAAAAADIIiAAAAAJIIigAAAAAYBEUAAAAAJEk2zbsCAAttu2zbvKvAIttO3jbvKgAAAKtk2T2KquqgqvpgVf3xeH5MVb2vqnZU1UVVdfAof9B4vmPM37rc9wYAAABgdmZx69mLkly/4Pm5SV7V3Y9KckeSM0f5mUnuGOWvGssBAAAAsEYsKyiqqqOSfF+S14/nleR7krxlLHJhktPH9Gnjecb8U8byAAAAAKwBy+1R9KtJ/lOSL4/nj0jy6e6+azy/JcmWMb0lyc1JMubfOZa/l6o6q6q2V9X2nTt3LrN6AAAAAOyr/Q6Kqur7k9ze3VfOsD7p7vO6+8TuPnHz5s2zfGkAAAAA9mI5v3r2lCQ/UFWnJnlwkq9J8uokh1bVptFr6Kgkt47lb01ydJJbqmpTkkOSfHIZ7w8AAADADO13j6Lu/s/dfVR3b03y3CTv7u4fSvKeJM8ci52R5O1j+uLxPGP+u7u79/f9AQAAAJitWfzq2WIvS/KSqtqRaQyi80f5+UkeMcpfkuTsFXhvAAAAAPbTcm49u0d3X5bksjF9Y5In7maZLyZ51izeDwAAAIDZW4keRQAAAACsQ4IiAAAAAJIIigAAAAAYBEUAAAAAJBEUAQAAADAIigAAAABIIigCAAAAYBAUAQAAAJBEUAQAAADAICgCAAAAIImgCAAAAIBBUAQAAABAEkERAAAAAIOgCAAAAIAkgiIAAAAABkERAAAAAEkERQAAAAAMgiIAAAAAkgiKAAAAABgERQAAAAAkERQBAAAAMAiKAAAAAEgiKAIAAABgEBQBAAAAkERQBAAAAMAgKAIAAAAgiaAIAAAAgEFQBAAAAEASQREAAAAAg6AIAAAAgCSCIgAAAACGTfOuAMzTtsu2zbsKAAAAsGboUQQAAABAEkERAAAAAIOgCAAAAIAkgiIAAAAAhv0Oiqrq6Kp6T1VdV1XXVtWLRvnDq+qSqrphPB42yquqXlNVO6rqQ1V1wqw+BAAAAADLt5weRXcl+dnuPi7JSUleWFXHJTk7yaXdfWySS8fzJHlGkmPHv7OSvG4Z7w0AAADAjO13UNTdt3X3VWP6s0muT7IlyWlJLhyLXZjk9DF9WpI39OSKJIdW1ZH7+/4AAAAAzNZMxiiqqq1Jjk/yviRHdPdtY9bHkxwxprckuXnBareMMgAAAADWgGUHRVX1sCRvTfLi7v7Mwnnd3Un6fr7eWVW1vaq279y5c7nVAwAAAGAfLSsoqqoHZgqJ3tjdbxvFn9h1S9l4vH2U35rk6AWrHzXK7qW7z+vuE7v7xM2bNy+negAAAADcD8v51bNKcn6S67v7VxbMujjJGWP6jCRvX1D+/PHrZycluXPBLWoAAAAAzNmmZaz7lCQ/kuSaqrp6lP18knOSvLmqzkxyU5Jnj3nvSHJqkh1JvpDkBct4bwCANWXbZdvmXQV2Y9vJ2+ZdBQBYV/Y7KOruP09Se5h9ym6W7yQv3N/3AwAAAGBlzeRXzwAAAABY/wRFAAAAACRZ3hhFABwAjLuyNhl3BQCAlaBHEQAAAABJBEUAAAAADIIiAAAAAJIIigAAAAAYDGYNAACsGj+SsDb5kQRgFz2KAAAAAEiiRxEArEuuyAMAsBIERQAAALDGuCi0Nh0It2m69QwAAACAJIIiAAAAAAZBEQAAAABJBEUAAAAADIIiAAAAAJIIigAAAAAYBEUAAAAAJBEUAQAAADAIigAAAABIIigCAAAAYNg07woAAMBK2XbZtnlXAQDWFT2KAAAAAEgiKAIAAABgcOsZAADAAc5tmsAuehQBAAAAkERQBAAAAMAgKAIAAAAgiaAIAAAAgEFQBAAAAEASQREAAAAAg6AIAAAAgCSCIgAAAAAGQREAAAAASQRFAAAAAAyCIgAAAACSCIoAAAAAGFY9KKqqp1fVR6tqR1WdvdrvDwAAAMDurWpQVFUHJfmNJM9IclyS51XVcatZBwAAAAB2b7V7FD0xyY7uvrG7v5Tk95Octsp1AAAAAGA3Vjso2pLk5gXPbxllAAAAAMzZpnlXYLGqOivJWePp56rqo/OszwwdnuQf512JNU4b7Z322TvtszRttHfaZ2naaO+0z9K00d5pn6Vpo73TPkvTRnunfZbwi/nFjdJGj9zTjNUOim5NcvSC50eNsnt093lJzlvNSq2Gqtre3SfOux5rmTbaO+2zd9pnadpo77TP0rTR3mmfpWmjvdM+S9NGe6d9lqaN9k77LO1AaKPVvvXsA0mOrapjqurgJM9NcvEq1wEAAACA3VjVHkXdfVdV/WSSdyY5KMkF3X3tatYBAAAAgN1b9TGKuvsdSd6x2u+7Bmy42+lWgDbaO+2zd9pnadpo77TP0rTR3mmfpWmjvdM+S9NGe6d9lqaN9k77LG3Dt1F197zrAAAAAMAasNpjFAEAAACwRgmKWBFVdWhV/ccxfXJV/fG868T6tnCb4r6q6qer6vqqeuO868L6tWA7uqOqzp53fdaTqnp9VR0373qstqo6uqreU1XXVdW1VfWiUf7wqrqkqm4Yj4eN8qqq11TVjqr6UFWdMMq/u6quXvDvi1V1+hw/2kzMqn3GvH9VVe8a39HrqmrrnD7WTO1HG31zVf1VVf1zVb100Ws9vao+OtrPPuwAMePv2blV9eHx7znz+kyzNOP2uXvBfnpd/yiVY+e9c+sZK2IcvPxxd39bVZ2c5KXd/f1LrHNQd9+9CtVjHVq4Tc27LmtRVX0kyVO7+5ZlvEZl+rvw5dnVjPVkFtsRB5aqOjLJkd19VVV9dZIrk5ye5EeTfKq7zxkn7Id198uq6tQkP5Xk1CRPSvLq7n7Sotd8eJIdSY7q7i+s3qeZvVm2T1VdluSV3X1JVT0syZfXe/sk+9VGX5vkkWOZO7r7l8frHJTkb5J8b5JbMv3a8vO6+7pV/kissll9z6rq+5K8OMkzkjwoyWVJTunuz6zyR5qpGe+HPtfdD5vH55i13R3zVNWm7r5rjtVaM/QompGqekVVvXjB81dW1Yuq6ueq6gMjjf3FMe+hVfV/q+qvN1Javcg5Sb6xqq5O8ktJHlZVb6mqj1TVG8cJaarq70Zyf1WSZ1XV08ZVoquq6g/GgVCq6vFV9WdVdWVVvXPs8Dasqto6Eu7fHsn/u6rqq6rqcVV1xdie/nBX8n+AuGebqqrfqaofSJLRDheM6R+rqleO6ZcsuCL04vlVe+VV1W8m+YYkf1JVP1tVfzS2kSuq6jFjmW214MrraJet499Hq+oNST6c5Oj5fIqVY/+8bxZtRz9TVb9eVYdU1U1V9YCxzEOr6uaqemBVfWNV/enYL19eVd8830+wena3nVTVZVV1YlU9sqars4dX1QNG2zxt3nVeKd19W3dfNaY/m+T6JFuSnJbkwrHYhZlOSjLK39CTK5Icupu/6c9M8icbIQSZVfvU1FttU3dfMl7rcxuhfZL730bdfXt3fyDJvyx6qScm2dHdN3b3l5L8/niNdWkP+5n7HA/X1MPq/QvW21pV14zp3R4/j/3VuVX1/qr6m6r6N/P6nLMww/3QcUne2913dffnk3woydNX75OsjBXaT69ri4557qyq36uqv0jye+M7dPk4H72qqr5jrHPy+O7s7pz2CVX1l+P7+v6q+uqqOqiqfmnBseZ/mONHvt8ERbNzQZLnJ8k4oH5uko8nOTbTH67HJXl8VX1nph3OP3T3Y0fviD+dS41X1tlJ/ra7H5fk55IcnymhPy7Tl/IpC5b9ZHefkOT/JfmFTMnuCUm2J3lJVT0wya8leWZ3Pz5TW79ylT7HPB2b5De6+1uTfDrJDyZ5Q5KXdfdjklyT5OXzq96qW7hNvTPJroOaLZm2q4yy91bV45O8INNVkJOS/PuqOn51q7t6uvvHk/xDku9OsjXJB8c28vOZtpmlHJvktd39rd1904pVdH7sn/fBou3ojlF2Z5Krk3zXWOz7k7yzu/8l0y9+/NTYL780yWtXu85ztMftZHyHzk3yuiQ/m+S67n7XfKq5umrq+Xl8kvclOaK7bxuzPp7kiDG9JcnNC1a7ZZQt9Nwkb1q5ms7HMtvn0Uk+XVVvq6oPjpOPg1an5qtnH9toT/Zl21pPdrefuc/xcHd/JMnBVXXMWO85SS7ah+PnTd39xEzH5xvmeHKZ37O/TvL0qnpIVR2e6e/hhrqANoP99IOrantNFyNPX/kar4xFxzyvynQu8dTufl6S25N87zgffU6S1yxY9T7ntFV1cJKLkryoux+b5KlJ/inJmUnu7O4nJHlCpvORY7JObJp3BTaK7v67qvrkOBk9IskHM20QTxvTSfKwTCcmlyf5X1V1bqZbaS6fR51X2ft3deurqZfR1iR/PuZdNB5PyvSl+4sRzh6c5K+SfFOSb0tyySg/KMmundpG9rHuvnpMX5nkG5Mc2t1/NsouTPIH86jYGnB5khePK6zXJTlsXOl4cpKfTvJjSf5wXA1KVb0tU4j0wT283kbyrzOFiunud1fVI6rqa5ZY56ZxxWhDsn9etosyHSi9J9MJ/Gtr6u35HUn+YOyXk6mb/oHimizaTha0Q7r79VX1rCQ/nimI3PDGNvHWJC/u7s8sao+uqn0a62Dsy7890wWBDWMG7bMp09+x45P8fabv5Y8mOX9FKjwHs9qGNpB77WcyBfh7Oh5+c6b99Dnj8TlZ+vj5bePxykzH5evecreh7n5XVT0hyV8m2ZnpPGTDDIsxo+/YI7v71qr6hiTvrqpruvtvV6jKq+ni7v6nMf3AJL9eVY/L9P//6AXL7e6c9s4kt42ejulxq2JNvYkfU1XPHOsekulY82Mr+klmRFA0W6/P9Ef76zKl9qck+Z/d/VuLF6xpULBTk/z3qrq0u1+xmhWdg39eMH137r3tfX48VpJLRpJ7j6r69iTXdveTV7aKa87iNjt0TvVYc8YfqEMzXW17b5KHJ3l2ks9192cX/uHjHnfl3r1IH7xg+vPZ+Oyf99/FSf5HTePGPD7Ju5M8NMmnRw+/A053/83i7WTh/Kp6SJKjxtOHJfnsKldxVY2eC29N8sbu3nXy+YmqOrK7bxvhz+2j/Nbc+wr9UaNsl2dnCvoX31a0bs2ofTYlubq7bxyv+UeZLrBtiKDofrbRniy1ba0ri/czmfa9ezoevihTcP+2adW+YR+On3cdZy4+Ll+XZrUf6u5XZvS8qqr/k2ncq3Vvhu2z6/HGmsZNOz7JRgiKFh4L/0ySTyR5bKZj5y8umLe3c9rFKlPP63V54cOtZ7P1h5lOXJ+Q6UrYO5P8WH1lnJ0tVfW1VfX1Sb7Q3f870/g9J+zpBdexzyb56vu5zhWZuu89Krnn3uxHJ/loks1V9eRR/sCq+taZ1nZ9uDPJHfWV+8h/JMmf7WX5jWbxNnVFpq6f783UC+Sl4zHj8fTRdfihSf7dgnkb3eVJfiiZ7qVO8o/jysbfZexrxoHnuun6OiP2z/upuz+XaVDYV2fqPXP32KY+NnrN7PqFlMfOs56raR+2k3OTvDHJf03y26tcvVVVUzJ/fpLru/tXFsy6OMkZY/qMJG9fUP78sc2clKlb/sJeDs/LBrrtbIbt84FM44RsHst9T6YetevefrTRnnwgybFVdcy4FeS54zXWpd3sZ56UPRwPjx4ddyf5L/lKT/0D5vh5Vt+zmsaUecR4zcckeUySdX/r8Azb57CqetB4zcMzDSWyIfZDixySqYfQlzOdby11m+9Hkxw5eqOlpvGJNmU61vyJEdKlqh49zkvWhXWfHq8l3f2lqnpPpqusdyd5V1V9S5K/Gj0cPpfkh5M8KskvVdWXMw3E9xPzqvNK6e5PVtVfVNWHM92j+Yl9WGdnVf1okjft2gkl+YVxReWZSV5TVYdk2m5/Ncm1K1P7Ne2MJL85rlbfmGkcngPCom3qTzIFIk/r7h1VdVOmXkWXj2WvqqrfTbJrcMfXd/eBcNtZkmxLckFVfSjJF/KVA4C3Zvqjf22m+9I3xBWyfbXc/XNVvSLJ9u5etycdy3RRpltdT15Q9kNJXldVv5Cpm/bvZxrf4UDw7bnvdrLrl5e+K1Mg+ZTuvruqfrCqXtDdvzO/6q6op2Q6kL6mpm74yTQ+2jlJ3lxVZya5KVNPoSR5R6YeEjsy7aPu+TtW09gZR2djXQSZSfuMbemlSS4dJ31XZuOEkPerjarq6zKNY/k1Sb5c048VHDdupfnJTCdnByW5oLvX87Hi7vYzd2XPx8MXZQqUjknu+bt3oBw/z2o/9MAku24l/kySH+6N8QtYs2qfb0nyW2ObfECSc3pj/qrga5O8taqen2lssL32vB/fteck+bWq+qpM575PzdSbfWuSq8Z+e2e+MmD4mlfdB9rtviunpkFSr0ryrO6+Yd71AWBi/wwAAPvGrWczUtOgujuSXOokBGDtsH8GAIB9p0cRAAAAAEn0KAIAAABgEBQBAAAAkERQBAAAAMAgKAIAAAAgiaAIAAAAgEFQBAAAAECS5P8D9CuTwy+dvA8AAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 1440x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib\n",
        "matplotlib.rc('figure', figsize=[20,5])\n",
        "plt.hist(temp_reply_list, 10,\n",
        "         histtype='bar',\n",
        "         facecolor='g',\n",
        "         alpha=0.5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6JvdTkvv9nwa"
      },
      "source": [
        "**Check the average length of the replies**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "colab_type": "code",
        "id": "XfvPGKsHxWzW",
        "outputId": "820f166b-ccad-499a-8d7a-4e6e65083889"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of email don' have any reply : 0\n",
            "**************************************************\n",
            "Max length : 3\n",
            "**************************************************\n",
            "Min Length : 1\n",
            "**************************************************\n",
            "Average Length : 1.0416666666666667\n",
            "**************************************************\n",
            "unique replies in the data 155\n",
            "--------------------------------------------------\n",
            "Distribution of the words\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib\n",
        "matplotlib.rc('figure', figsize=[10,5])\n",
        "#Getting the length of each Answer\n",
        "len_answers = data[\"reply\"].values\n",
        "#len_answers = data[\"reply_length\"].values\n",
        "\n",
        "#converting datatype to string\n",
        "len_str_arr = []\n",
        "for sentence in len_answers:\n",
        "  len_str_arr.append(len(sentence.split()))\n",
        "\n",
        "\n",
        "temp_arr = []\n",
        "for indx in len_answers:\n",
        "  if indx == 0:\n",
        "    continue\n",
        "  else:\n",
        "    temp_arr.append(indx)\n",
        "\n",
        "no_reply_counter = 0 \n",
        "print(\"number of email don' have any reply\", end = ' : ')\n",
        "print(no_reply_counter)\n",
        "print('*' * 50)\n",
        "\n",
        "print('Max length', end = ' : ')\n",
        "print(max(list(len_str_arr)))\n",
        "print('*' * 50)\n",
        "\n",
        "print('Min Length', end = ' : ')\n",
        "print(min(list(len_str_arr)))\n",
        "print('*' * 50)\n",
        "\n",
        "print(\"Average Length\", end = ' : ')\n",
        "print((sum(list(len_str_arr)))/(len(list(len_str_arr))))\n",
        "print('*' * 50)\n",
        "\n",
        "\n",
        "# need to get all the unique replies in the dataset\n",
        "all_unique_replies = list(set(data['reply'].values))\n",
        "print('unique replies in the data',len(all_unique_replies))\n",
        "\n",
        "\n",
        "print('-' * 50)\n",
        "print(\"Distribution of the words\")\n",
        "print('-' * 50)\n",
        "\n",
        "len_str_arr.sort()\n",
        "plt.hist(len_str_arr, 200,\n",
        "         histtype='bar',\n",
        "         facecolor='r',\n",
        "         alpha=0.5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xOGUS8J6-J7L"
      },
      "source": [
        "So here we are seeing the number of words in the replies \n",
        "are 1 only\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9-_fsek1mmcm"
      },
      "source": [
        "Here we should have less unique replies but due to shortage of the data we can' remove more data from the data corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "XmobS9OImxk-"
      },
      "outputs": [],
      "source": [
        "#Here I'll try to use only the data where replies repeated for more then 5 times"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QujyL73prseT"
      },
      "source": [
        "**Check for emails/Question**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "rtqw89lviMMr"
      },
      "outputs": [],
      "source": [
        "all_questions = data['question'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "O6l_1hStAynl"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Preprocessing Questions \n",
        "#Remove the full stops from the dataframe answers\n",
        "\n",
        "bad_chars = [';', ':', '!', \"*\",'.',')','(','?']\n",
        "\n",
        "preprocessed_question = []\n",
        "for question in all_questions:\n",
        "  for i in bad_chars : \n",
        "    question = question.replace(i, '')\n",
        "  preprocessed_question.append(question)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "17OJ8r9UbMbe"
      },
      "source": [
        "**Words stemming**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "wTp7oYSKYVH2"
      },
      "outputs": [],
      "source": [
        "#Performing stammering here\n",
        "# We are having less data\n",
        "from nltk.stem import PorterStemmer\n",
        "porter = PorterStemmer()\n",
        "stemmed_sent = []\n",
        "for sent in preprocessed_question:\n",
        "  word_arr = []\n",
        "  for word in sent.split():\n",
        "    word_arr.append(porter.stem(word))\n",
        "  temp_str = \"\"\n",
        "  for words in word_arr:\n",
        "    temp_str += words + \" \"\n",
        "  stemmed_sent.append(temp_str)\n",
        "\n",
        "data['question'] = stemmed_sent  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "ir4gNpv7bmW3"
      },
      "outputs": [],
      "source": [
        "#trimming the string the dataframe  \n",
        "#because after removal of the special character trimming might have lost\n",
        "data = data.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "colab_type": "code",
        "id": "3VxzMC4FSJJK",
        "outputId": "77e7f027-bfbe-4957-84b6-6ad7e550ec68"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>reply</th>\n",
              "      <th>q</th>\n",
              "      <th>reply_length</th>\n",
              "      <th>question_length</th>\n",
              "      <th>repeated_reply_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>when did beyonc leav destini s child and becom...</td>\n",
              "      <td>2003</td>\n",
              "      <td>nan</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>when did beyonc releas danger in love</td>\n",
              "      <td>2003</td>\n",
              "      <td>nan</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>how mani grammi award did beyonc win for her f...</td>\n",
              "      <td>five</td>\n",
              "      <td>nan</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>to set the record for grammi how mani did beyo...</td>\n",
              "      <td>six</td>\n",
              "      <td>nan</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>when did beyonc take a hiatu in her career and...</td>\n",
              "      <td>2010</td>\n",
              "      <td>nan</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>75</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             question reply    q  \\\n",
              "2   when did beyonc leav destini s child and becom...  2003  nan   \n",
              "11              when did beyonc releas danger in love  2003  nan   \n",
              "12  how mani grammi award did beyonc win for her f...  five  nan   \n",
              "17  to set the record for grammi how mani did beyo...   six  nan   \n",
              "19  when did beyonc take a hiatu in her career and...  2010  nan   \n",
              "\n",
              "    reply_length  question_length  repeated_reply_count  \n",
              "2              1               12                    47  \n",
              "11             1                7                    47  \n",
              "12             1               12                   140  \n",
              "17             1               11                    99  \n",
              "19             1               15                    75  "
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "colab_type": "code",
        "id": "mHaWHSRzSOzv",
        "outputId": "206d67e3-d186-4b45-8f1f-8c690b3a6f67"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(data['question'].values[0].split())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556
        },
        "colab_type": "code",
        "id": "bHv6ShjNiMSf",
        "outputId": "674f0c14-ef01-4c65-b771-0d41b970eb3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of email don' have any reply : 1\n",
            "**************************************************\n",
            "Max length : 229\n",
            "**************************************************\n",
            "Min Length : 2\n",
            "**************************************************\n",
            "Average Length : 52.312569676700114\n",
            "**************************************************\n",
            "No of unique questions : 152\n",
            "**************************************************\n",
            "--------------------------------------------------\n",
            "Distribution of the words\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib\n",
        "matplotlib.rc('figure', figsize=[10,5])\n",
        "#Getting the length of each Answer\n",
        "len_questions = data[\"question\"].str.len()\n",
        "\n",
        "#converting datatype to string\n",
        "\n",
        "len_str_arr = []\n",
        "for data_ in data[\"question\"].values:\n",
        "  len_str_arr.append(len(data_.split()))\n",
        "\n",
        "\n",
        "no_reply_counter = 0\n",
        "for num in len_questions:\n",
        "  if num == 0:\n",
        "    no_reply_counter += 1\n",
        "\n",
        "temp_arr = []\n",
        "for indx in len_questions:\n",
        "  if indx == 0:\n",
        "    continue\n",
        "  else:\n",
        "    temp_arr.append(indx)\n",
        "    \n",
        "print(\"number of email don' have any reply\", end = ' : ')\n",
        "print(no_reply_counter)\n",
        "print('*' * 50)\n",
        "\n",
        "print('Max length', end = ' : ')\n",
        "print(max(list(len_questions)))\n",
        "print('*' * 50)\n",
        "\n",
        "print('Min Length', end = ' : ')\n",
        "print(min(list(temp_arr)))\n",
        "print('*' * 50)\n",
        "\n",
        "print(\"Average Length\", end = ' : ')\n",
        "print((sum(list(len_questions)))/(len(list(len_questions))))\n",
        "print('*' * 50)\n",
        "\n",
        "print(\"No of unique questions\", end = ' : ')\n",
        "print(len(list(set(len_questions))))\n",
        "print('*' * 50)\n",
        "\n",
        "\n",
        "print('-' * 50)\n",
        "print(\"Distribution of the words\")\n",
        "print('-' * 50)\n",
        "len_str_arr.sort()\n",
        "plt.hist(len_str_arr, 200,\n",
        "         histtype='bar',\n",
        "         facecolor='b',\n",
        "         alpha=0.5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "C0mF14vFAvSO"
      },
      "source": [
        "As we can see that number of maximum numner of words in  questions have 5 wordsw <br>\n",
        "and most of them are in range 3-10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BbghnR-HLKmN"
      },
      "source": [
        "check maximum number of words in question \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "D5zJkJevk2GF"
      },
      "source": [
        "**Feature Engineering**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "02c38hlHnDiJ"
      },
      "outputs": [],
      "source": [
        "# https://gist.github.com/sebleier/554280\n",
        "#contains all the stop words this we'll use to count the stop words available in the question\n",
        "\n",
        "stopwords_all = set(['br', 'the', 'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n",
        "            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n",
        "            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n",
        "            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n",
        "            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n",
        "            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n",
        "            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n",
        "            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n",
        "            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n",
        "            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n",
        "            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n",
        "            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n",
        "            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n",
        "            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n",
        "            'won', \"won't\", 'wouldn', \"wouldn't\",'no', 'nor', 'not'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "ts5wVPoKk8B-"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'data' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6008/2663077996.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mlen_str_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'question'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m   \u001b[0mlen_str_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
          ]
        }
      ],
      "source": [
        "#here we'll get the length of the sentence\n",
        "# we need to get the length of the question here\n",
        "\n",
        "len_str_arr = []\n",
        "for sentence in data['question'].values:\n",
        "  len_str_arr.append(len(sentence.split()))\n",
        "\n",
        "data[\"question_length\"]= len_str_arr\n",
        "\n",
        "\n",
        "#Here we'll get the number of stop words in the sentences\n",
        "stop_word_count = []\n",
        "for sentence in data['question'].values:\n",
        "  count = 0\n",
        "  for words in sentence:\n",
        "    if words in stopwords_all:\n",
        "      count += 1\n",
        "  stop_word_count.append(count)\n",
        "\n",
        "data['question_stop_words'] = stop_word_count\n",
        "\n",
        "# divide further for -ve and +ve stop words\n",
        "# positive = \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Here we'll take if days are there in the data corpus\n",
        "#This will help in prediction of weekday easily\n",
        "\n",
        "days = ['mon','tue','wed','thr','fri','sat','sun','sunday','monday','tuesday','wednesday','friday','thursday','saturday','sunday']    \n",
        "\n",
        "\n",
        "days_in_data = []\n",
        "for sentence in data['question'].values:\n",
        "  count = 0\n",
        "  for words in sentence:\n",
        "    if words in days:\n",
        "      count += 1\n",
        "  days_in_data.append(count)\n",
        "\n",
        "data['contains_days'] = days_in_data\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#We can take tense also into concideration\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FSktpcGeCxF-"
      },
      "source": [
        "#Data Preperation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Fab8YSEriMUB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CKgGutTXiRaK"
      },
      "source": [
        "So we'll repeat the replies after test and train bifercation else we'll get data leakage problem "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "colab_type": "code",
        "id": "3mREQeVzp25w",
        "outputId": "d7a54a35-5d66-4608-e26a-4df6f2d79bbf"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>reply</th>\n",
              "      <th>q</th>\n",
              "      <th>reply_length</th>\n",
              "      <th>question_length</th>\n",
              "      <th>repeated_reply_count</th>\n",
              "      <th>question_stop_words</th>\n",
              "      <th>contains_days</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>when did beyonc leav destini s child and becom...</td>\n",
              "      <td>2003</td>\n",
              "      <td>nan</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>47</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>when did beyonc releas danger in love</td>\n",
              "      <td>2003</td>\n",
              "      <td>nan</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>47</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             question reply    q  \\\n",
              "2   when did beyonc leav destini s child and becom...  2003  nan   \n",
              "11              when did beyonc releas danger in love  2003  nan   \n",
              "\n",
              "    reply_length  question_length  repeated_reply_count  question_stop_words  \\\n",
              "2              1               12                    47                   24   \n",
              "11             1                7                    47                   11   \n",
              "\n",
              "    contains_days  \n",
              "2               0  \n",
              "11              0  "
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "7nby-PwP4_zH"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'data' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6008/3149073215.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'q'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
          ]
        }
      ],
      "source": [
        "data = data.drop('q',axis= 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "colab_type": "code",
        "id": "3xX3LNoL5G4X",
        "outputId": "1495d5f8-683c-456f-f0be-6da026003d5d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>reply</th>\n",
              "      <th>reply_length</th>\n",
              "      <th>question_length</th>\n",
              "      <th>repeated_reply_count</th>\n",
              "      <th>question_stop_words</th>\n",
              "      <th>contains_days</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>when did beyonc leav destini s child and becom...</td>\n",
              "      <td>2003</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>47</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>when did beyonc releas danger in love</td>\n",
              "      <td>2003</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>47</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>how mani grammi award did beyonc win for her f...</td>\n",
              "      <td>five</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>140</td>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>to set the record for grammi how mani did beyo...</td>\n",
              "      <td>six</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>99</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>when did beyonc take a hiatu in her career and...</td>\n",
              "      <td>2010</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>75</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             question reply  reply_length  \\\n",
              "2   when did beyonc leav destini s child and becom...  2003             1   \n",
              "11              when did beyonc releas danger in love  2003             1   \n",
              "12  how mani grammi award did beyonc win for her f...  five             1   \n",
              "17  to set the record for grammi how mani did beyo...   six             1   \n",
              "19  when did beyonc take a hiatu in her career and...  2010             1   \n",
              "\n",
              "    question_length  repeated_reply_count  question_stop_words  contains_days  \n",
              "2                12                    47                   24              0  \n",
              "11                7                    47                   11              0  \n",
              "12               12                   140                   26              0  \n",
              "17               11                    99                   22              0  \n",
              "19               15                    75                   24              0  "
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FRKD36AqXoZF"
      },
      "source": [
        "Let see which are top repeated replies "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "1FTj8QJqgy3d"
      },
      "outputs": [],
      "source": [
        "#Here we'll repeat the data set which are having less replies "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "dloXSKiM5PBr"
      },
      "outputs": [],
      "source": [
        "## Similartly you can do preprocessing for review summary also.\n",
        "#splitting the data(X and y) where X is the preprocessed reviews ad y is the score\n",
        "X_Quest = data['question']\n",
        "x_question_length = data['question_length']\n",
        "x_question_stop_words = data['question_stop_words']\n",
        "x_contains_days = data['contains_days']\n",
        "y = data['reply']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "colab_type": "code",
        "id": "tiPcBVHeJZyS",
        "outputId": "9b6adeed-2135-480a-898c-4eca48f9b2cf"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>reply</th>\n",
              "      <th>reply_length</th>\n",
              "      <th>question_length</th>\n",
              "      <th>repeated_reply_count</th>\n",
              "      <th>question_stop_words</th>\n",
              "      <th>contains_days</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>when did beyonc leav destini s child and becom...</td>\n",
              "      <td>2003</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>47</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>when did beyonc releas danger in love</td>\n",
              "      <td>2003</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>47</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>how mani grammi award did beyonc win for her f...</td>\n",
              "      <td>five</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>140</td>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>to set the record for grammi how mani did beyo...</td>\n",
              "      <td>six</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>99</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>when did beyonc take a hiatu in her career and...</td>\n",
              "      <td>2010</td>\n",
              "      <td>1</td>\n",
              "      <td>15</td>\n",
              "      <td>75</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             question reply  reply_length  \\\n",
              "2   when did beyonc leav destini s child and becom...  2003             1   \n",
              "11              when did beyonc releas danger in love  2003             1   \n",
              "12  how mani grammi award did beyonc win for her f...  five             1   \n",
              "17  to set the record for grammi how mani did beyo...   six             1   \n",
              "19  when did beyonc take a hiatu in her career and...  2010             1   \n",
              "\n",
              "    question_length  repeated_reply_count  question_stop_words  contains_days  \n",
              "2                12                    47                   24              0  \n",
              "11                7                    47                   11              0  \n",
              "12               12                   140                   26              0  \n",
              "17               11                    99                   22              0  \n",
              "19               15                    75                   24              0  "
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "yez2heU7JRKS"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'data' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6008/1425043031.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'reply'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
          ]
        }
      ],
      "source": [
        "X = data.drop('reply',axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "iXomn3x_dMZd"
      },
      "outputs": [],
      "source": [
        "%matplotlib notebook\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "# https://gist.github.com/greydanus/f6eee59eaf1d90fcb3b534a25362cea4\n",
        "# https://stackoverflow.com/a/14434334\n",
        "# this function is used to update the plots for each epoch and error\n",
        "def plt_dynamic(x, vy, ty, ax, colors=['b']):\n",
        "    ax.plot(x, vy, 'b', label=\"Validation Loss\")\n",
        "    ax.plot(x, ty, 'r', label=\"Train Loss\")\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    fig.canvas.draw()\n",
        "    plt.savefig(name)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "BRAUgaj-psIn"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'X' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6008/3209045997.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#splitting the data into train and test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
          ]
        }
      ],
      "source": [
        "#splitting the data into train and test\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.10, random_state = 42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "colab_type": "code",
        "id": "biuLXKtqaqTX",
        "outputId": "6d521ff9-40aa-49bc-c095-5403f2584519"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "149\n"
          ]
        }
      ],
      "source": [
        "test = set(y_test.values)\n",
        "train = set(y_train.values)\n",
        "count = 0\n",
        "for reply_test in test:\n",
        "  for reply_train in train:\n",
        "    if reply_train == reply_test:\n",
        "      count += 1\n",
        "      break;\n",
        "print(count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "colab_type": "code",
        "id": "sNYtaZKJbK0o",
        "outputId": "d7fe737d-854a-42cd-95f6-92f45d69de5c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "149"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GXosuIy7bO_c"
      },
      "source": [
        "So we are having all the data(replies) which is there is test data are also avaialble in train data(replies)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HiudxFoBieKo"
      },
      "source": [
        "#Here we'll repeat the replies for train set only"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QcZ1rsuYh0AP"
      },
      "source": [
        "After this, We'll repeat the number of replies as we need less classification but more data so we'll check which reply is repeated how many times and will set an threshold to repeat the number of replies\n",
        "\n",
        "Here we'll do upsampling of the data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "A4sAfaj0XoZT"
      },
      "outputs": [],
      "source": [
        "reply_list = list(data['reply'].values)\n",
        "reply_dict = {i:reply_list.count(i) for i in reply_list}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "jNtz0kNvXoZh"
      },
      "outputs": [],
      "source": [
        "from collections import OrderedDict\n",
        "reply_dict_sorted = OrderedDict(sorted(reply_dict.items(), key=lambda x: x[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "mJvU9Dp_XoZv"
      },
      "outputs": [],
      "source": [
        "reply = []\n",
        "keys = []\n",
        "for item in reply_dict_sorted.items():\n",
        "  reply.append(item[0])\n",
        "  keys.append(item[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "6j5tF7MlXoZ4"
      },
      "outputs": [],
      "source": [
        "reply.reverse()\n",
        "keys.reverse()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "MIrqQrPXXoaA"
      },
      "outputs": [],
      "source": [
        "#top 10 reply\n",
        "reply_ = reply[:]\n",
        "keys_ = keys[:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "colab_type": "code",
        "id": "J6dttsmvgBH_",
        "outputId": "4f6d43fa-59de-4dce-e3a9-9646c21ab72e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'yes': 886, 'three': 248, 'no': 241, 'two': 236, 'four': 183, 'yes.': 170, 'five': 140, 'six': 99, '2007': 88, '2006': 85, '2010': 75, 'seven': 74, '2009': 73, '2005': 70, 'france': 65, 'eight': 63, 'one': 61, '2013': 61, '2011': 59, '2004': 58, '2008': 55, '2012': 53, 'china': 50, 'nine': 50, 'paris': 50, 'french': 48, '2003': 47, 'germany': 46, '1991': 46, '2002': 46, 'english': 46, '2001': 45, '2014': 45, 'no.': 43, '20': 43, '19th': 40, '14': 40, 'latin': 39, '1994': 39, '1997': 39, '12': 39, '2015': 39, '1990': 38, '1999': 38, 'german': 37, '1992': 37, 'world war ii': 37, '1949': 37, 'united states': 37, 'london': 37, '1989': 36, '16': 36, '2000': 36, 'italy': 36, 'british': 35, '1968': 35, '10': 35, '1998': 34, 'greek': 34, '13': 34, 'europe': 34, 'white': 34, '30': 34, 'soviet union': 33, '19th century': 33, '1971': 33, 'japan': 33, 'spanish': 33, '1978': 32, '1979': 32, '1990s': 32, 'india': 32, '1995': 32, '1988': 31, 'ten': 31, 'russia': 30, '1960s': 30, '1950': 30, '15': 30, '1963': 30, 'england': 30, '18': 30, 'third': 30, 'britain': 29, '1974': 29, '1976': 29, '2': 29, '1996': 29, '1985': 28, '1956': 28, '1980s': 28, '1987': 28, '1960': 28, '1977': 28, '1970s': 28, '1972': 28, '3': 28, '17': 28, '1948': 27, '1993': 27, '1965': 27, '20%': 27, 'new york': 27, '1983': 27, 'spain': 26, 'tito': 26, 'new delhi': 26, 'christian': 26, '40': 26, 'half': 26, '200,000': 26, 'madonna': 26, '1986': 25, '1962': 25, '11': 25, 'rome': 25, 'melbourne': 24, '1967': 24, '1970': 24, '1954': 24, '1964': 24, '1966': 24, '1959': 24, '1936': 24, 'new york city': 24, '25': 24, '1981': 24, '1861': 23, '1984': 23, '10%': 23, 'christianity': 23, '1931': 23, '1955': 23, '1952': 23, 'manhattan': 23, '10,000': 23, '50': 23, '1980': 22, '1914': 22, '1939': 22, '1982': 22, '1973': 22, '1913': 22, '25%': 22, '90%': 22, 'green': 21, '19': 21, '1917': 21, '20th century': 21, 'canada': 21, '1918': 21, '1958': 21, '1946': 21, '6': 21, 'eleven': 21}\n"
          ]
        }
      ],
      "source": [
        "res = dict(zip(reply_, keys_)) \n",
        "print(str(res))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "pf11PBBnirkt"
      },
      "outputs": [],
      "source": [
        "df_concat = pd.concat([x_train, y_train], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 95
        },
        "colab_type": "code",
        "id": "FnkucmxV5uIx",
        "outputId": "9136b530-520f-4eb8-dea3-598f280331b3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>reply_length</th>\n",
              "      <th>question_length</th>\n",
              "      <th>repeated_reply_count</th>\n",
              "      <th>question_stop_words</th>\n",
              "      <th>contains_days</th>\n",
              "      <th>reply</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>80597</th>\n",
              "      <td>when were mosaic pavement uncov at the bizer m...</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>47</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "      <td>2003</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                question  reply_length  \\\n",
              "80597  when were mosaic pavement uncov at the bizer m...             1   \n",
              "\n",
              "       question_length  repeated_reply_count  question_stop_words  \\\n",
              "80597                9                    47                   19   \n",
              "\n",
              "       contains_days reply  \n",
              "80597              0  2003  "
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_concat.head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "colab_type": "code",
        "id": "Da93CdIRirX6",
        "outputId": "56c6a39d-4b97-49cf-f794-d8e7e2d20429"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 155/155 [00:00<00:00, 179.50it/s]\n"
          ]
        }
      ],
      "source": [
        "#We'll run for loop for every value and upsample every reply in the dataframe \n",
        "column_names = ['question','reply_length','repeated_reply_count','question_length','question_stop_words','contains_days','reply']\n",
        "temp_df = pd.DataFrame(columns = column_names)\n",
        "for item in tqdm(res):\n",
        "  # get the this data from the dataframe \n",
        "    df_class = df_concat[df_concat['reply'] == item]\n",
        "    df_over = df_class#.sample(100, replace=True)\n",
        "    frames = [temp_df, df_over]\n",
        "    temp_df = pd.concat(frames)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "colab_type": "code",
        "id": "UTJZj_lsta6j",
        "outputId": "4819122c-8069-4d71-e204-21a306da796e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(6458, 7)\n"
          ]
        }
      ],
      "source": [
        "#Here we checking the shape for theoversampled data\n",
        "print(temp_df.shape)\n",
        "\n",
        "#append yes replies too in the temp_df, as we ignored yes there in the above \n",
        "\n",
        "df_yes_reply = df_concat[df_concat['reply'] == 'yes']\n",
        "\n",
        "frame = [df_yes_reply,temp_df]\n",
        "\n",
        "upsample_data = pd.concat(frame)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "colab_type": "code",
        "id": "6L0KsH3x79ec",
        "outputId": "daae850f-9bca-4344-d97a-90815e48fe73"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(7255, 7)"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "upsample_data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BBomafMz8DFT"
      },
      "source": [
        "so now we increased dataset from 7K to 121K"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "16G80nZW8JOe"
      },
      "source": [
        "Again we need to divide the dataframe into x_train and y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "YpC9ysFe8StF"
      },
      "outputs": [],
      "source": [
        "x_train = upsample_data.drop('reply',axis = 1)\n",
        "y_train = upsample_data['reply']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "V2Zjqk1aK8Vw"
      },
      "outputs": [],
      "source": [
        " words = []\n",
        "for text in x_train['question'].values:\n",
        "  words += text.split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "dP4ebysiNXwJ"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "count = Counter(words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "colab_type": "code",
        "id": "DPXNCXd-OlHl",
        "outputId": "6a8ef8be-7d4c-453a-9be6-cda97953d3ba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "collections.Counter"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "VMk2WAxEOqUJ"
      },
      "outputs": [],
      "source": [
        "#Taking only top 5K data \n",
        "sorted_words_arr = count.most_common(5000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "dEEE-gSATRuZ"
      },
      "outputs": [],
      "source": [
        "sorted_arr = []\n",
        "for index in range(0,len(sorted_words_arr)):\n",
        "  sorted_arr.append(sorted_words_arr[index][0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "evPjXJ-qPWqK"
      },
      "outputs": [],
      "source": [
        "sentGlobal = []\n",
        "for sentence in x_train['question'].values:\n",
        "  words_Local = []\n",
        "  for words in sentence.split():\n",
        "    if words in sorted_arr:\n",
        "      words_Local.append(sorted_arr.index(words) + 1)\n",
        "\n",
        "  sentGlobal.append(words_Local)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Z9fDLOyKUs0D"
      },
      "outputs": [],
      "source": [
        "sentGlobal_test = []\n",
        "for sentence in x_test['question'].values:\n",
        "  words_Local = []\n",
        "  for words in sentence.split():\n",
        "    if words in sorted_arr:\n",
        "      words_Local.append(sorted_arr.index(words) + 1)\n",
        "\n",
        "  sentGlobal_test.append(words_Local)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "LsJvfp7VriT0"
      },
      "outputs": [],
      "source": [
        "x_train_question = sentGlobal\n",
        "x_test_question = sentGlobal_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "colab_type": "code",
        "id": "edjVv6FPVNci",
        "outputId": "cfc67b83-97a0-4f5a-8ba8-fa8191ae8fc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(7255, 10)\n"
          ]
        }
      ],
      "source": [
        "# truncate and/or pad input sequences\n",
        "from keras.preprocessing import sequence\n",
        "#As maximum length is 9 we'll take 10 as maximum review length\n",
        "max_review_length = 10\n",
        "#Here we padded the sentence and truncated at the end. \n",
        "X_train_quest = sequence.pad_sequences(x_train_question, maxlen=max_review_length,padding='post',truncating='post',value=0)\n",
        "X_test_quest = sequence.pad_sequences(x_test_question, maxlen=max_review_length,padding='post',truncating='post',value=0)\n",
        "print(X_train_quest.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "q9ekkyUJiEG1"
      },
      "source": [
        "Here we need to tokenize the (full sentence) into 1 token for the test data<br>\n",
        "We need all the unique setences available in the data and create a matrix where we an mark which reply is in which position"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "colab_type": "code",
        "id": "ClufFz3RLyKQ",
        "outputId": "ca0b7c1b-5342-4215-9648-39fc33adb56a"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'y' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6008/2640751886.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtokenized_reply_sentences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# need to get all the unique replies in the dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mall_unique_replies\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'unique replies in the data'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_unique_replies\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'y' is not defined"
          ]
        }
      ],
      "source": [
        "tokenized_reply_sentences = []\n",
        "# need to get all the unique replies in the dataset\n",
        "all_unique_replies = list(set(y.values))\n",
        "print('unique replies in the data',len(all_unique_replies))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "colab_type": "code",
        "id": "c9Qkhx_3-dHS",
        "outputId": "0bef8d0f-a156-4f63-c625-2c2b3bd94be3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7255"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train.shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eCOASFyFMoTn"
      },
      "source": [
        "So we exact same number of replies in our data set "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "xJPOyVcggLdH"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'all_unique_replies' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6008/3104610744.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0moutput_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_unique_replies\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m# this replies are coming from train data only\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# from word to token we can get\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0moutput_token_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mreverse_output_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moutput_token_index\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'all_unique_replies' is not defined"
          ]
        }
      ],
      "source": [
        "output_words = sorted(list(all_unique_replies))# this replies are coming from train data only \n",
        "# from word to token we can get\n",
        "output_token_index = dict([(word, i+1) for i, word in enumerate(output_words)])\n",
        "reverse_output_index = dict((i, word) for word, i in output_token_index.items())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "cSK0fqyUR0iW"
      },
      "outputs": [],
      "source": [
        "def generate_batch(X,y, batch_size):\n",
        "    while True:\n",
        "        for j in range(0, len(X), batch_size):\n",
        "                    rows,cols = (len(X),(len(list(set(data['reply'].values)))+1)) \n",
        "                    output_data = np.zeros((rows, cols),dtype='float32')\n",
        "                    for (i, (input_text, target_text)) in enumerate(zip(X[j:j+ batch_size], y[j:j + batch_size])):\n",
        "                        #creatinf 2D matrix for thr replies\n",
        "                        output_data[i,output_token_index[target_text]] = 1\n",
        "                    return output_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "xxI5L0OJSSsZ"
      },
      "outputs": [],
      "source": [
        "Y_train = generate_batch(X_train_quest,y_train,len(X_train_quest))  \n",
        "Y_test = generate_batch(X_test_quest,y_test,len(X_test_quest))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "colab_type": "code",
        "id": "RrJFp3gky-ep",
        "outputId": "b6773672-eb08-497a-c565-6833f383890a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(7255, 156)"
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "N3_A1dfu_LEb"
      },
      "outputs": [],
      "source": [
        "#For question text we'are embedding\n",
        "from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional,Concatenate,TimeDistributed\n",
        "from keras.layers import Input, LSTM, Embedding, Dense\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Dropout, BatchNormalization, Input, Flatten, concatenate,Embedding,RepeatVector\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "colab_type": "code",
        "id": "Q-RMY-dh5PMK",
        "outputId": "6ea366f0-c1df-4f85-f3c8-8344b17d63fa"
      },
      "outputs": [],
      "source": [
        "#Question Length\n",
        "\n",
        "input_data_question_length = Input(shape=(1,),name=\"question_length\")\n",
        "# layer_question_length = Embedding(42,42,trainable=True)(input_data_question_length)\n",
        "x = BatchNormalization()(input_data_question_length)\n",
        "flattened_question_length = Dense(128, activation='relu')(x)\n",
        "# flattened_question_length = input_data_question_length#Flatten()(input_data_question_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "lakoiIgq9AAL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "colab_type": "code",
        "id": "u5w_RJgI-atN",
        "outputId": "df8380d7-6a50-487f-c4f0-29bf15020361"
      },
      "outputs": [],
      "source": [
        "#Question stop words\n",
        "input_data_question_stop_words = Input(shape=(1,),name=\"question_stop_words\")\n",
        "# layer_question_stop_words = Embedding(74,74,trainable=True)(input_data_question_stop_words)\n",
        "x = BatchNormalization()(input_data_question_stop_words)\n",
        "x = Dropout(0.3)(x)\n",
        "flattened_question_stop_words = Dense(128, activation='relu')(x)\n",
        "# flattened_question_stop_words = (input_data_question_stop_words)#Flatten()(layer_question_stop_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "r1ZD_Yqu3dpk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "nD6hCMbC3d-J"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Question contains days\n",
        "input_data_question_contains_days = Input(shape=(1,),name=\"contains_days\")\n",
        "# layer_question_contains_days = Embedding(1,1,trainable=True)(input_data_question_contains_days)\n",
        "x = BatchNormalization()(input_data_question_contains_days)\n",
        "flattened_question_contains_days = Dense(128, activation='relu')(x)\n",
        "# flattened_question_contains_days =  (input_data_question_contains_days)#Flatten()(input_data_question_contains_days)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "o6DDoXiy3dZ-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "CjXqOkGUBVAN"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'output_token_index' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6008/3436424815.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0membedding_vecor_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmax_review_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mvocab_len\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_token_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m  \u001b[1;31m# how much dimension of output we want form the embedding layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mencoder_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# mentioning the input shape row and collumns are still null\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'output_token_index' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "embedding_vecor_length = 64\n",
        "max_review_length = 10\n",
        "vocab_len = len(output_token_index)\n",
        " # how much dimension of output we want form the embedding layer\n",
        "encoder_inputs = Input(shape=(None,)) # mentioning the input shape row and collumns are still null\n",
        "# model = Sequential()\n",
        "# model.add(Embedding(vocab_len + 1, latent_dim, input_length=vocab_len))\n",
        "# model.add(Embedding(vocab_len + 1, embedding_vecor_length, input_length=max_review_length))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "colab_type": "code",
        "id": "L5AfMeqH_f8D",
        "outputId": "55393745-7419-4d0b-a6f6-ddffc7b06d7c"
      },
      "outputs": [],
      "source": [
        "from keras.layers.recurrent import LSTM\n",
        "input_text =  Input(shape=(None,),name=\"input_text\")\n",
        "# try batch normaization here // it;ll be according to word i guess\n",
        "embedded_layer = Embedding(vocab_len + 1, embedding_vecor_length, input_length=max_review_length)\n",
        "x = embedded_layer(input_text)\n",
        "x = Bidirectional(LSTM(128,return_sequences=True))(x)\n",
        "x = BatchNormalization()(x)\n",
        "# x = Bidirectional(LSTM(64,return_sequences=True))(x)\n",
        "x = Dropout(0.2)(x) \n",
        "x = LSTM(64,return_sequences=True)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.1)(x)\n",
        "\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = LSTM(256,return_sequences=True)(x)\n",
        "flatted_text = Flatten()(Dense(128,activation=\"relu\",kernel_initializer=\"he_normal\")(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "MrdlmnxIsw3k"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from keras import backend as K\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "0ew3gLgJZGFu"
      },
      "outputs": [],
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def f1(y_true, y_pred):\n",
        "    def recall(y_true, y_pred):\n",
        "        \"\"\"Recall metric.\n",
        "\n",
        "        Only computes a batch-wise average of recall.\n",
        "\n",
        "        Computes the recall, a metric for multi-label classification of\n",
        "        how many relevant items are selected.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "    def precision(y_true, y_pred):\n",
        "        \"\"\"Precision metric.\n",
        "\n",
        "        Only computes a batch-wise average of precision.\n",
        "\n",
        "        Computes the precision, a metric for multi-label classification of\n",
        "        how many selected items are relevant.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "    precision = precision(y_true, y_pred)\n",
        "    recall = recall(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "colab_type": "code",
        "id": "3aTzSquDOr4y",
        "outputId": "090ca1a0-526a-4418-e3bc-c7337287a063"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'flattened_question_length' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6008/283958097.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mflattened_question_length\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mflattened_question_stop_words\u001b[0m\u001b[1;33m,\u001b[0m    \u001b[0mflatted_text\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"relu\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkernel_initializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"he_normal\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'flattened_question_length' is not defined"
          ]
        }
      ],
      "source": [
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.models import Sequential, Model, load_model\n",
        "#concatinating \n",
        "\n",
        "\n",
        "data = concatenate([flattened_question_length ,flattened_question_stop_words,    flatted_text])\n",
        "data = Dense(256,activation=\"relu\",kernel_initializer=\"he_normal\")(data)\n",
        "\n",
        "data = Dropout(0.3)(data) \n",
        "data = BatchNormalization()(data)\n",
        "data = Dense(256,activation=\"relu\",kernel_initializer=\"he_normal\")(data)\n",
        "data = Dropout(0.2)(data)\n",
        "data = BatchNormalization()(data)\n",
        "data = Dense(512,activation=\"relu\",kernel_initializer=\"he_normal\")(data)\n",
        "data = Dropout(0.1)(data)\n",
        " \n",
        "outputs = Dense(156, activation='softmax')(data)\n",
        "model = Model(inputs = [input_data_question_length,   input_data_question_stop_words,  input_text],outputs= outputs)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[f1_m,precision_m, recall_m])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "xKy2z600hXed"
      },
      "outputs": [],
      "source": [
        "train_model = [x_train['question_length'],x_train['question_stop_words'],X_train_quest]#,   label_encoder_train_sub_sub_category,   label_encoder_train_sub_category,     label_encoder_train_grade    ,label_encoder_train_teacher_prefix   ,label_encoder_train]\n",
        "\n",
        "test_model = [x_test['question_length'],x_test['question_stop_words'],X_test_quest]#,   label_encoder_test_sub_sub_category,   label_encoder_test_sub_category,     label_encoder_test_grade    ,label_encoder_test_teacher_prefix   ,label_encoder_test]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "colab_type": "code",
        "id": "CQDatdNyykQY",
        "outputId": "8a588df3-3e6a-499e-eb9e-cbf2b67ae0e6"
      },
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "cannot import name 'plot_model' from 'keras.utils' (C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\__init__.py)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15628/2186772897.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'model.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mImportError\u001b[0m: cannot import name 'plot_model' from 'keras.utils' (C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\__init__.py)"
          ]
        }
      ],
      "source": [
        "from keras.utils import plot_model\n",
        "plot_model(model, to_file='model.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "XQtiPuYTMhob"
      },
      "outputs": [],
      "source": [
        "from tensorflow.python.keras.callbacks import TensorBoard\n",
        "from time import time\n",
        "from keras.callbacks import ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "FP3W9xAOMhfT"
      },
      "outputs": [],
      "source": [
        "# !wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "# !unzip ngrok-stable-linux-amd64.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "C05Whp1HMhV8"
      },
      "outputs": [],
      "source": [
        "# LOG_DIR = './log'\n",
        "# get_ipython().system_raw(\n",
        "#     'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "#     .format(LOG_DIR)\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "IAdDvzYUMhJC"
      },
      "outputs": [],
      "source": [
        "# get_ipython().system_raw('./ngrok http 6006 &')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "aKFnrcAuMsQR"
      },
      "outputs": [],
      "source": [
        "# ! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "#     \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "OJW1taNGMsEj"
      },
      "outputs": [],
      "source": [
        "\n",
        "# from keras.callbacks import TensorBoard\n",
        "# batch_size=20\n",
        "# tbCallBack = TensorBoard(log_dir='./log', histogram_freq=1,\n",
        "#                          write_graph=True,\n",
        "#                          write_grads=True,\n",
        "#                          batch_size=batch_size,\n",
        "#                          write_images=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "colab_type": "code",
        "id": "290z-O_YPRyb",
        "outputId": "c5b4aa28-2855-4a75-f3d9-488eb81d9a6b"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15628/4262524158.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# istory = model.fit(train_model,Y_train,batch_size=30,epochs=120,validation_data=(test_model,Y_test),verbose=1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m350\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "# istory = model.fit(train_model,Y_train,batch_size=30,epochs=120,validation_data=(test_model,Y_test),verbose=1)\n",
        "history = model.fit(train_model,Y_train,batch_size=350,epochs=60,validation_data=(test_model,Y_test),verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "yDUoCxM6rmaT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        },
        "colab_type": "code",
        "id": "3TG4Ssl7s9Sq",
        "outputId": "619d696d-a730-48db-f729-6e7d4761fd44"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "unexpected EOF while parsing (Temp/ipykernel_15628/467500536.py, line 1)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\admin\\AppData\\Local\\Temp/ipykernel_15628/467500536.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    (type(X_train_quest)\u001b[0m\n\u001b[1;37m                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
          ]
        }
      ],
      "source": [
        "(type(X_train_quest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "colab_type": "code",
        "id": "6Ru4MlEdALmx",
        "outputId": "07f9af9e-9aba-49b1-ecab-8c4c8c2ee92c"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'history' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15628/3369499301.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#loss graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matplotlib'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'b'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'g'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'loss_train'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'b'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'loss_test'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'g'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ],
      "source": [
        "#loss graph\n",
        "%matplotlib inline\n",
        "plt.plot(history.history['loss'], 'b')\n",
        "plt.plot(history.history['val_loss'], 'g')\n",
        "plt.legend({'loss_train': 'b', 'loss_test':'g'})\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "colab_type": "code",
        "id": "4S3tXu79AS4p",
        "outputId": "e912e368-d43c-41d9-b755-04fe3ca5fb55"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "#auc_roc graph\n",
        "plt.legend({'train_roc_auc': 'b', 'test_roc_auc':'g'})\n",
        "plt.plot(history.history['f1_m'], 'b')\n",
        "plt.plot(history.history['val_f1_m'], 'g')\n",
        "plt.legend({'f1_micro_train': 'b', 'f1_micro_test':'g'})\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "xa4NOKXRhfUT"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "filename = 'model.sav'\n",
        "pickle.dump(model, open(filename, 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "AEoyRK5XhwPb"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "filename = 'history'\n",
        "pickle.dump(model, open(filename, 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "pqLVIoJ_OI4n"
      },
      "outputs": [],
      "source": [
        "pred = model.predict(test_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "colab_type": "code",
        "id": "XYFn5OUkOJig",
        "outputId": "0aeac98d-682d-47f8-d568-1464e6b844b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question 1\n",
            "how mani major medic school doe london boast\n",
            "\n",
            "\n",
            "real answer\n",
            "five\n",
            "\n",
            "\n",
            "predicted Answers\n",
            "three\n",
            "two\n",
            "four\n",
            "\n",
            "\n",
            "********\n",
            "Question 2\n",
            "which confeder cup did brasilia host\n",
            "\n",
            "\n",
            "real answer\n",
            "2013\n",
            "\n",
            "\n",
            "predicted Answers\n",
            "2014\n",
            "1936\n",
            "1954\n",
            "\n",
            "\n",
            "********\n",
            "Question 3\n",
            "what percentag of children in a survey of peopl in hyderabad were underweight\n",
            "\n",
            "\n",
            "real answer\n",
            "20%\n",
            "\n",
            "\n",
            "predicted Answers\n",
            "25%\n",
            "10%\n",
            "20%\n",
            "\n",
            "\n",
            "********\n",
            "Question 4\n",
            "in what year were big chang made to the ansi\n",
            "\n",
            "\n",
            "real answer\n",
            "1960\n",
            "\n",
            "\n",
            "predicted Answers\n",
            "1959\n",
            "1967\n",
            "1984\n",
            "\n",
            "\n",
            "********\n",
            "Question 5\n",
            "how mani region health administr exist in portug\n",
            "\n",
            "\n",
            "real answer\n",
            "five\n",
            "\n",
            "\n",
            "predicted Answers\n",
            "six\n",
            "five\n",
            "two\n",
            "\n",
            "\n",
            "********\n",
            "Question 6\n",
            "are there mani roma in romania\n",
            "\n",
            "\n",
            "real answer\n",
            "no\n",
            "\n",
            "\n",
            "predicted Answers\n",
            "no.\n",
            "no\n",
            "yes.\n",
            "\n",
            "\n",
            "********\n",
            "Question 7\n",
            "how mani polic district wa pari divid into\n",
            "\n",
            "\n",
            "real answer\n",
            "16\n",
            "\n",
            "\n",
            "predicted Answers\n",
            "two\n",
            "three\n",
            "four\n",
            "\n",
            "\n",
            "********\n",
            "Question 8\n",
            "in what year wa a statu dedic to freddi mercuri unveil in montreux\n",
            "\n",
            "\n",
            "real answer\n",
            "1996\n",
            "\n",
            "\n",
            "predicted Answers\n",
            "1962\n",
            "2009\n",
            "2011\n",
            "\n",
            "\n",
            "********\n",
            "Question 9\n",
            "what is the offici languag of bern\n",
            "\n",
            "\n",
            "real answer\n",
            "german\n",
            "\n",
            "\n",
            "predicted Answers\n",
            "english\n",
            "german\n",
            "french\n",
            "\n",
            "\n",
            "********\n",
            "Question 10\n",
            "what year did david goldstein report that unlik male ashkenazi lineag the femal lineag in ashkenazi jewish commun did not seem to be middl eastern\n",
            "\n",
            "\n",
            "real answer\n",
            "2002\n",
            "\n",
            "\n",
            "predicted Answers\n",
            "2003\n",
            "2010\n",
            "2015\n",
            "\n",
            "\n",
            "********\n",
            "Question 11\n",
            "how mani day after paul vi elect did he announc he would continu the vatican ii\n",
            "\n",
            "\n",
            "real answer\n",
            "six\n",
            "\n",
            "\n",
            "predicted Answers\n",
            "one\n",
            "2000\n",
            "three\n",
            "\n",
            "\n",
            "********\n",
            "Question 12\n",
            "how old wa schwarzenegg when he start bodybuild\n",
            "\n",
            "\n",
            "real answer\n",
            "15\n",
            "\n",
            "\n",
            "predicted Answers\n",
            "20\n",
            "18\n",
            "17\n",
            "\n",
            "\n",
            "********\n",
            "Question 13\n",
            "when wa tito brought to russia as a prison of war\n",
            "\n",
            "\n",
            "real answer\n",
            "1918\n",
            "\n",
            "\n",
            "predicted Answers\n",
            "1974\n",
            "1959\n",
            "1985\n",
            "\n",
            "\n",
            "********\n",
            "Question 14\n",
            "what year did sub saharan africa have the highest rate of child labour\n",
            "\n",
            "\n",
            "real answer\n",
            "2010\n",
            "\n",
            "\n",
            "predicted Answers\n",
            "1997\n",
            "1963\n",
            "2010\n",
            "\n",
            "\n",
            "********\n",
            "Question 15\n",
            "do otter eat fish\n",
            "\n",
            "\n",
            "real answer\n",
            "yes\n",
            "\n",
            "\n",
            "predicted Answers\n",
            "yes\n",
            "no\n",
            "yes.\n",
            "\n",
            "\n",
            "********\n",
            "Question 16\n",
            "when wa lee kuan yew prime minist of singapor\n",
            "\n",
            "\n",
            "real answer\n",
            "1959\n",
            "\n",
            "\n",
            "predicted Answers\n",
            "2013\n",
            "1996\n",
            "2007\n",
            "\n",
            "\n",
            "********\n",
            "Question 17\n",
            "what year did simon cowel announc that he wa leav american idol\n",
            "\n",
            "\n",
            "real answer\n",
            "2010\n",
            "\n",
            "\n",
            "predicted Answers\n",
            "2015\n",
            "2009\n",
            "2012\n",
            "\n",
            "\n",
            "********\n",
            "Question 18\n",
            "the most popul citi in the unit state is which citi\n",
            "\n",
            "\n",
            "real answer\n",
            "new york city\n",
            "\n",
            "\n",
            "predicted Answers\n",
            "britain\n",
            "russia\n",
            "europe\n",
            "\n",
            "\n",
            "********\n",
            "Question 19\n",
            "mani differ type of interact can be control by how mani button\n",
            "\n",
            "\n",
            "real answer\n",
            "one\n",
            "\n",
            "\n",
            "predicted Answers\n",
            "two\n",
            "five\n",
            "three\n",
            "\n",
            "\n",
            "********\n",
            "Question 20\n",
            "how mani galleri are present in the plymouth citi museum and art galleri\n",
            "\n",
            "\n",
            "real answer\n",
            "six\n",
            "\n",
            "\n",
            "predicted Answers\n",
            "one\n",
            "three\n",
            "five\n",
            "\n",
            "\n",
            "********\n",
            "Question 21\n",
            "how mani commun fm radio station are there in southampton\n",
            "\n",
            "\n",
            "real answer\n",
            "2\n",
            "\n",
            "\n",
            "predicted Answers\n",
            "200,000\n",
            "seven\n",
            "five\n",
            "\n",
            "\n",
            "********\n",
            "Question 22\n",
            "how mani time wa schwarzenegg award the mr olympia titl\n",
            "\n",
            "\n",
            "real answer\n",
            "seven\n",
            "\n",
            "\n",
            "predicted Answers\n",
            "two\n",
            "three\n",
            "four\n",
            "\n",
            "\n",
            "********\n",
            "Question 23\n",
            "what wa the origin plan launch year for twilight princess\n",
            "\n",
            "\n",
            "real answer\n",
            "2005\n",
            "\n",
            "\n",
            "predicted Answers\n",
            "2007\n",
            "2005\n",
            "1996\n",
            "\n",
            "\n",
            "********\n",
            "Question 24\n",
            "how mani u s invest bank significantli increas their financi leverag from to\n",
            "\n",
            "\n",
            "real answer\n",
            "five\n",
            "\n",
            "\n",
            "predicted Answers\n",
            "one\n",
            "10\n",
            "six\n",
            "\n",
            "\n",
            "********\n",
            "Question 25\n",
            "is uruguay s warmest month june\n",
            "\n",
            "\n",
            "real answer\n",
            "no\n",
            "\n",
            "\n",
            "predicted Answers\n",
            "yes\n",
            "no\n",
            "yes.\n",
            "\n",
            "\n",
            "********\n",
            "Question 26\n",
            "when wa mac s xserv server discontinu\n",
            "\n",
            "\n",
            "real answer\n",
            "2011\n",
            "\n",
            "\n",
            "predicted Answers\n",
            "1989\n",
            "1981\n",
            "1966\n",
            "\n",
            "\n",
            "********\n",
            "Question 27\n",
            "how big wa the popul of the aztec cit of tenochtitlan\n",
            "\n",
            "\n",
            "real answer\n",
            "200,000\n",
            "\n",
            "\n",
            "predicted Answers\n",
            "25%\n",
            "half\n",
            "90%\n",
            "\n",
            "\n",
            "********\n",
            "Question 28\n",
            "when did russia say they will be send more troop to tajikistan\n",
            "\n",
            "\n",
            "real answer\n",
            "2015\n",
            "\n",
            "\n",
            "predicted Answers\n",
            "1993\n",
            "1979\n",
            "1992\n",
            "\n",
            "\n",
            "********\n",
            "Question 29\n",
            "what year did dell stop sell product through physic retail\n",
            "\n",
            "\n",
            "real answer\n",
            "1994\n",
            "\n",
            "\n",
            "predicted Answers\n",
            "2011\n",
            "2008\n",
            "2007\n",
            "\n",
            "\n",
            "********\n",
            "Question 30\n",
            "in what year did the european parliament adopt a resolut to remov race from all offici text\n",
            "\n",
            "\n",
            "real answer\n",
            "1996\n",
            "\n",
            "\n",
            "predicted Answers\n",
            "2006\n",
            "2007\n",
            "2008\n",
            "\n",
            "\n",
            "********\n",
            "Question 31\n",
            "how mani troop parachut into mao counti\n",
            "\n",
            "\n",
            "real answer\n",
            "15\n",
            "\n",
            "\n",
            "predicted Answers\n",
            "nine\n",
            "3\n",
            "18\n",
            "\n",
            "\n",
            "********\n",
            "Question 32\n",
            "what year wa the standard output sensit techniqu introduc\n",
            "\n",
            "\n",
            "real answer\n",
            "2006\n",
            "\n",
            "\n",
            "predicted Answers\n",
            "1964\n",
            "2007\n",
            "1985\n",
            "\n",
            "\n",
            "********\n",
            "Question 33\n",
            "are cello construct with glue\n",
            "\n",
            "\n",
            "real answer\n",
            "yes\n",
            "\n",
            "\n",
            "predicted Answers\n",
            "yes.\n",
            "no\n",
            "yes\n",
            "\n",
            "\n",
            "********\n",
            "Question 34\n",
            "which year wa use for estim in the report\n",
            "\n",
            "\n",
            "real answer\n",
            "2013\n",
            "\n",
            "\n",
            "predicted Answers\n",
            "2010\n",
            "2014\n",
            "2001\n",
            "\n",
            "\n",
            "********\n",
            "Question 35\n",
            "when did el nuevo herald leav miami\n",
            "\n",
            "\n",
            "real answer\n",
            "2013\n",
            "\n",
            "\n",
            "predicted Answers\n",
            "1984\n",
            "1981\n",
            "1991\n",
            "\n",
            "\n",
            "********\n",
            "Question 36\n",
            "when did negoti start to regul mine in antarctica\n",
            "\n",
            "\n",
            "real answer\n",
            "1983\n",
            "\n",
            "\n",
            "predicted Answers\n",
            "1988\n",
            "1955\n",
            "1990\n",
            "\n",
            "\n",
            "********\n",
            "Question 37\n",
            "in what year wa the final trolley rout in new haven convert to a bu line\n",
            "\n",
            "\n",
            "real answer\n",
            "1948\n",
            "\n",
            "\n",
            "predicted Answers\n",
            "2003\n",
            "2000\n",
            "2010\n",
            "\n",
            "\n",
            "********\n",
            "Question 38\n",
            "in what citi is the georg inn locat\n",
            "\n",
            "\n",
            "real answer\n",
            "london\n",
            "\n",
            "\n",
            "predicted Answers\n",
            "london\n",
            "new york city\n",
            "paris\n",
            "\n",
            "\n",
            "********\n",
            "Question 39\n",
            "in what citi wa the world s first featur film shot in\n",
            "\n",
            "\n",
            "real answer\n",
            "melbourne\n",
            "\n",
            "\n",
            "predicted Answers\n",
            "london\n",
            "paris\n",
            "new york city\n",
            "\n",
            "\n",
            "********\n",
            "Question 40\n",
            "how mani women spoke out publicli about misconduct on schwarzenegg s part\n",
            "\n",
            "\n",
            "real answer\n",
            "six\n",
            "\n",
            "\n",
            "predicted Answers\n",
            "20\n",
            "15\n",
            "eleven\n",
            "\n",
            "\n",
            "********\n",
            "Question 41\n",
            "less than of the world s total grid electr wa gener by solar energi in what year\n",
            "\n",
            "\n",
            "real answer\n",
            "2013\n",
            "\n",
            "\n",
            "predicted Answers\n",
            "britain\n",
            "germany\n",
            "russia\n",
            "\n",
            "\n",
            "********\n",
            "Question 42\n",
            "how mani time did coptic patriarch shenouda iii meet with paul vi in\n",
            "\n",
            "\n",
            "real answer\n",
            "three\n",
            "\n",
            "\n",
            "predicted Answers\n",
            "three\n",
            "two\n",
            "four\n",
            "\n",
            "\n",
            "********\n",
            "Question 43\n",
            "when were switzerland women grant the right to vote on a feder level\n",
            "\n",
            "\n",
            "real answer\n",
            "1971\n",
            "\n",
            "\n",
            "predicted Answers\n",
            "1980s\n",
            "20th century\n",
            "19th century\n",
            "\n",
            "\n",
            "********\n",
            "Question 44\n",
            "what countri creat an integr system for adgb\n",
            "\n",
            "\n",
            "real answer\n",
            "britain\n",
            "\n",
            "\n",
            "predicted Answers\n",
            "spain\n",
            "russia\n",
            "france\n",
            "\n",
            "\n",
            "********\n",
            "Question 45\n",
            "where is charanka solar park\n",
            "\n",
            "\n",
            "real answer\n",
            "india\n",
            "\n",
            "\n",
            "predicted Answers\n",
            "soviet union\n",
            "britain\n",
            "british\n",
            "\n",
            "\n",
            "********\n",
            "Question 46\n",
            "how much of pakistan s paper product doe punjab manufactur\n",
            "\n",
            "\n",
            "real answer\n",
            "90%\n",
            "\n",
            "\n",
            "predicted Answers\n",
            "20%\n",
            "10%\n",
            "half\n",
            "\n",
            "\n",
            "********\n",
            "Question 47\n",
            "when did the carolina hurrican win the stanley cup\n",
            "\n",
            "\n",
            "real answer\n",
            "2006\n",
            "\n",
            "\n",
            "predicted Answers\n",
            "2004\n",
            "2009\n",
            "1996\n",
            "\n",
            "\n",
            "********\n",
            "Question 48\n",
            "when wa the concept of educ through recreat chang and expand\n",
            "\n",
            "\n",
            "real answer\n",
            "20th century\n",
            "\n",
            "\n",
            "predicted Answers\n",
            "19th century\n",
            "1956\n",
            "2011\n",
            "\n",
            "\n",
            "********\n",
            "Question 49\n",
            "doe romania border hungari\n",
            "\n",
            "\n",
            "real answer\n",
            "yes.\n",
            "\n",
            "\n",
            "predicted Answers\n",
            "yes\n",
            "no\n",
            "yes.\n",
            "\n",
            "\n",
            "********\n",
            "Question 50\n",
            "is otter a kind of mammal\n",
            "\n",
            "\n",
            "real answer\n",
            "yes.\n",
            "\n",
            "\n",
            "predicted Answers\n",
            "yes\n",
            "yes.\n",
            "no\n",
            "\n",
            "\n",
            "********\n"
          ]
        }
      ],
      "source": [
        "counter = 0\n",
        "accuracy_counter_test = 0\n",
        "for index in range(0,50):\n",
        "  counter += 1\n",
        "  print(\"Question\",counter)\n",
        "  print(x_test['question'].values[index])\n",
        "  print(\"\\n\")\n",
        "  print(\"real answer\")\n",
        "  p_0 = np.argmax(Y_test[index])\n",
        "  print(reverse_output_index[p_0])\n",
        "  print(\"\\n\")\n",
        "  print(\"predicted Answers\")\n",
        "  p_1 = np.argmax(pred[index])\n",
        "  token1 = reverse_output_index[p_1]\n",
        "  print(token1)\n",
        "  pred[index][p_1] = 0\n",
        "  p_2 = np.argmax(pred[index])\n",
        "  token2 = reverse_output_index[p_2]\n",
        "  print(token2)\n",
        "  pred[index][p_2] = 0\n",
        "  p_3 = np.argmax(pred[index])\n",
        "  token3 = reverse_output_index[p_3]\n",
        "  print(token3)\n",
        "  pred[index][p_3] = 0\n",
        "  print(\"\\n\")\n",
        "  print(\"*\"*8)\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EMQT6yOIIAnd"
      },
      "source": [
        "#Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uWrsBmDTIDQG"
      },
      "source": [
        "Here I got less accuracy in for the test but more accuracy for the train, <br>\n",
        "as in train dataset I oversampled the data which helped in getting more accuracy for the train dataset <br>\n",
        "But the test data set is not oversampled \n",
        "<br>\n",
        "<b> Even though the accuracy is less but see the answers above they are nearly the same intention <b>\n",
        "<br>\n",
        "\n",
        "<b> as model can't predict aptitute answers it tried to predict best of it <b>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CJRJMQJXJDHI"
      },
      "source": [
        "F1 Micro score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UqpY-YPyJFYD"
      },
      "source": [
        "for train it's 0.63 \n",
        "\n",
        "for test it's 0.2111"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Y57qRCbKJRdY"
      },
      "source": [
        "Loss Score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZeaA_g6pJS5j"
      },
      "source": [
        "for train it's 0.4105 <br>\n",
        "for test it's 6.98"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0mWnmwm4K4bU"
      },
      "source": [
        "Why I choosed the above approach"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gU4AkdJ3K8s0"
      },
      "source": [
        "I choosed above approach <b>(Multiclassification) not enocoder-decoder</b> as dataset is less and the chances of gramatical errors are more<br>\n",
        "and we need to predict short answers not long answers , as most of the suggestions are short in reality<br>\n",
        "<b>(Inspired from linkedin approach)</b>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4cihVxt4Jd3F"
      },
      "source": [
        "How the Things Worked"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Lbsa7xRcJ2pL"
      },
      "source": [
        "1. Loaded the data from multiple source and combined them all<br>\n",
        "2. We preprocessed the train data <br>\n",
        "3. took only the data which are repeated more than 20 times in the dataset which helped in less multiclassification \n",
        "and other thing is it helped in getting better grammar,as mostly reapeated questions will have better grammar\n",
        "4. because of previous step we got 155 multiclasses \n",
        "5. Divided the data into test and train \n",
        "6. Oversampled the train dataset on less repeated question which wil help in increasing the dataset and not let it biased towards more repeated answers\n",
        "7. did feature engineering ( Days, Stop words and question length)\n",
        "8. Predicted for the test dataset "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "R5cfdr3yMMpV"
      },
      "source": [
        "<h3>Conclusions:</h3>\n",
        " </br> \n",
        "LSTM with 1 layer is much simmilar to Layer 2 LSTM, No Drastic change in the accuracy </br> </br>\n",
        "LSTM with 2 layer took much more time compared to LSTM with 1 layer  without much change in accuracy</br></br>\n",
        "LSTM Worked Much better from all the previous models from ML as well as other NLP deep learning model </br> </br>\n",
        "LSTM have 3 layers operation inside it  </br> </br>\n",
        "LSTM is better form of Simple RNN </br> </br>\n",
        "\n",
        "\n",
        "<center> LSTM </center>\n",
        "</br>\n",
        "<b> 1st we got the data from and we preprocessed it </b></br>\n",
        "<b> 2nd we took the data(Sentences) and divided in train and test </b>\n",
        "</br>\n",
        "<b>3rd then we spliiteded the sentense into words </b>\n",
        "</br>\n",
        "<b> 4th we sorted thw words based on their occurance  and replaced it with the rank from 1- n </b>\n",
        "</br>\n",
        "<b>5th we choosed only top 5000 words from the ranking and words </b>\n",
        "</br>\n",
        "<b>6th change the words with ranks in x_test and x_train data </b>\n",
        "</br>\n",
        "<b>7th We'll take all sentence of same size so that batch can be created other wise it'll be very slow</b>\n",
        "</br>\n",
        "<b>8th created batch as input </b>\n",
        "</br>\n",
        "<b>9th Train a LSTM layer </b>\n",
        "</br> </br></br> </br></br> </br>\n",
        "<center> <h2>How LSTM Works </h2></b> </br></br>\n",
        "In LSTM \n",
        "we pass the input to layer 1 and it recur multiple times , with function time \n",
        "LSTM has 3 layers inside it</br> <b>\n",
        "Input ,output,forget</b>  </br></br>\n",
        "x and + are there which help me carring the data to further layer (like ResNet Skipping) so that original data can be preserved and if some data model didn' learn can be passed foward so that next time it may learn and can pass data to another layer without the loss \n",
        "\n",
        "</br></br>\n",
        "\n",
        "when we get the input as the output form previous interation or layer and the data as inout the we combine them and pass it throught sigmoid function which will (Ft) which tell how much to remember and forget it goes to (x)\n",
        "\n",
        "</br></br>\n",
        "\n",
        "and again now we thanwe take same input to previous sigmoid fucntiona  pass it to sigmoid and tanh and perform binary multiplication of output form sigmoid and tanh ( this tell how much input should impact the output of the layer)\n",
        "\n",
        "</br> </br>\n",
        "\n",
        "and the out put from previous layer is binary added to the output line \n",
        "</br></br>\n",
        "the again we put signoid layer which take (WiYt concated with w(Ot-1)) and goes to sigmoid layer and binary multiplied with the tanh of the ooutput line and give output as Yit which passes to another layer or to same with new iteration\n",
        "</br></br>\n",
        "\n",
        "\n",
        "\n",
        "Reference taken from https://cs224d.stanford.edu/reports/ZhouXu.pdf </center>\n",
        "\n",
        "\n",
        "\n",
        "in above models we tried multiple LSTM layers and neurons to train it better and get best output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "krYzg-24MNWP"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "Smart_reply_suggestion_multiclassification_approach.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
